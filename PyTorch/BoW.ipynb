{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24996e6b070>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np \n",
    "torch.manual_seed(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = autograd.Variable(torch.Tensor([[1, 2, 3], \n",
    "                                    [4, 5, 6],\n",
    "                                    [7, 8, 9]]), requires_grad = True)\n",
    "x2 = autograd.Variable(torch.Tensor([[1, 1, 1],\n",
    "                                    [1, 1, 1],\n",
    "                                    [1, 1, 1]]), requires_grad = True)\n",
    "x3 = x1 + x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ (\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
    "         (\"Give it to me\".split(), \"ENGLISH\"),\n",
    "         (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
    "         (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\") ]\n",
    "\n",
    "test_data = [ (\"Yo creo que si\".split(), \"SPANISH\"),\n",
    "              (\"it is lost on me\".split(), \"ENGLISH\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {}\n",
    "for sent, _ in data + test_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super(DummyClassifier, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        out = F.softmax(self.linear(bow_vec))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DummyClassifier(NUM_LABELS, VOCAB_SIZE)\n",
    "label_to_ix = { \"SPANISH\": 0, \"ENGLISH\": 1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6380, 0.3620]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhfar\\AppData\\Local\\Temp\\ipykernel_15804\\2323100239.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.softmax(self.linear(bow_vec))\n"
     ]
    }
   ],
   "source": [
    "sample = data[0]\n",
    "bow_vector = make_bow_vector(sample[0], word_to_ix)\n",
    "log_probs = model(autograd.Variable(bow_vector))\n",
    "print(log_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhfar\\AppData\\Local\\Temp\\ipykernel_15804\\2323100239.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.softmax(self.linear(bow_vec))\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "for epoch in range(1000):\n",
    "    for instance, label in data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.  We need to clear them out\n",
    "        # before each instance\n",
    "        model.zero_grad()\n",
    "        bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix))\n",
    "        target = autograd.Variable(make_target(label, label_to_ix))\n",
    "        log_probs = model(bow_vec)\n",
    "        loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9593, 0.0407]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0226, 0.9774]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([ 0.5695, -0.7037], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhfar\\AppData\\Local\\Temp\\ipykernel_15804\\2323100239.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.softmax(self.linear(bow_vec))\n"
     ]
    }
   ],
   "source": [
    "for instance, label in test_data:\n",
    "    bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix))\n",
    "    log_probs = model(bow_vec)\n",
    "    print(log_probs)\n",
    "print(next(model.parameters())[:,word_to_ix[\"creo\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd25ad554e4370e30797bf0235702b2665ad6fb58503cae9a34ffdb2391647b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
