{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from datagen import PNES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pnes_train, pnes_test, pnes_train_labels, pnes_test_labels = PNES('D:\\EEG\\PNES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8628]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 120\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 64), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "        \n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints. \n",
    "        self.fc1 = nn.Linear(4*2*7, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "        \n",
    "        # FC Layer\n",
    "        x = x.reshape(-1, 4*2*7)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = EEGNet().cuda(0)\n",
    "print(net.forward(Variable(torch.Tensor(np.random.rand(1, 1, 120, 64)).cuda(0))))\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y, params = [\"acc\"]):\n",
    "    results = []\n",
    "    batch_size = 100\n",
    "    \n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(int(len(X)/batch_size)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = Variable(torch.from_numpy(X[s:e]).cuda(0))\n",
    "        pred = model(inputs)\n",
    "        \n",
    "        predicted.append(pred.data.cpu().numpy())\n",
    "        \n",
    "        \n",
    "    inputs = Variable(torch.from_numpy(X).cuda(0))\n",
    "    predicted = model(inputs)\n",
    "    \n",
    "    predicted = predicted.data.cpu().numpy()\n",
    "    \n",
    "    for param in params:\n",
    "        if param == 'acc':\n",
    "            results.append(accuracy_score(Y, np.round(predicted)))\n",
    "        if param == \"auc\":\n",
    "            results.append(roc_auc_score(Y, predicted))\n",
    "        if param == \"recall\":\n",
    "            results.append(recall_score(Y, np.round(predicted)))\n",
    "        if param == \"precision\":\n",
    "            results.append(precision_score(Y, np.round(predicted)))\n",
    "        if param == \"fmeasure\":\n",
    "            precision = precision_score(Y, np.round(predicted))\n",
    "            recall = recall_score(Y, np.round(predicted))\n",
    "            results.append(2*precision*recall/ (precision+recall))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = np.random.rand(100, 1, 120, 64).astype('float32') # np.random.rand generates between [0, 1)\n",
    "y_train = np.round(np.random.rand(100).astype('float32')) # binary data, so we round it to 0 or 1.\n",
    "\n",
    "X_val = np.random.rand(100, 1, 120, 64).astype('float32')\n",
    "y_val = np.round(np.random.rand(100).astype('float32'))\n",
    "\n",
    "X_test = np.random.rand(100, 1, 120, 64).astype('float32')\n",
    "y_test = np.round(np.random.rand(100).astype('float32'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1, 120, 64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9403761504601842, 0.8367346938775511]\n",
      "Validation -  [0.46, 0.4827724358974359, 0.425531914893617]\n",
      "Test -  [0.49, 0.46153846153846156, 0.43956043956043955]\n",
      "\n",
      "Epoch  1\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.88, 0.9223689475790317, 0.8799999999999999]\n",
      "Validation -  [0.59, 0.5548878205128205, 0.5287356321839081]\n",
      "Test -  [0.46, 0.4154647435897436, 0.41304347826086957]\n",
      "\n",
      "Epoch  2\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9043617446978791, 0.86]\n",
      "Validation -  [0.52, 0.546474358974359, 0.45454545454545453]\n",
      "Test -  [0.44, 0.44310897435897434, 0.4042553191489362]\n",
      "\n",
      "Epoch  3\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9295718287314926, 0.8247422680412372]\n",
      "Validation -  [0.49, 0.5176282051282051, 0.38554216867469876]\n",
      "Test -  [0.38, 0.3826121794871795, 0.3404255319148936]\n",
      "\n",
      "Epoch  4\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9343737494997999, 0.8125]\n",
      "Validation -  [0.55, 0.5500801282051282, 0.4827586206896552]\n",
      "Test -  [0.44, 0.45232371794871795, 0.4285714285714286]\n",
      "\n",
      "Epoch  5\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9327731092436975, 0.7956989247311828]\n",
      "Validation -  [0.55, 0.5332532051282052, 0.47058823529411764]\n",
      "Test -  [0.48, 0.44190705128205127, 0.44680851063829785]\n",
      "\n",
      "Epoch  6\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9175670268107243, 0.8247422680412372]\n",
      "Validation -  [0.5, 0.4775641025641026, 0.4047619047619048]\n",
      "Test -  [0.42, 0.41185897435897434, 0.3829787234042554]\n",
      "\n",
      "Epoch  7\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9171668667466987, 0.8125]\n",
      "Validation -  [0.57, 0.5268429487179487, 0.5274725274725274]\n",
      "Test -  [0.38, 0.36618589743589747, 0.38]\n",
      "\n",
      "Epoch  8\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9375750300120047, 0.8297872340425532]\n",
      "Validation -  [0.49, 0.4859775641025641, 0.43956043956043955]\n",
      "Test -  [0.43, 0.3966346153846154, 0.43564356435643564]\n",
      "\n",
      "Epoch  9\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9187675070028011, 0.8163265306122448]\n",
      "Validation -  [0.55, 0.5532852564102564, 0.49438202247191015]\n",
      "Test -  [0.44, 0.422275641025641, 0.4042553191489362]\n",
      "\n",
      "Epoch  10\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9419767907162865, 0.8125]\n",
      "Validation -  [0.49, 0.4138621794871795, 0.41379310344827586]\n",
      "Test -  [0.45, 0.3978365384615385, 0.46601941747572817]\n",
      "\n",
      "Epoch  11\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9315726290516206, 0.8484848484848485]\n",
      "Validation -  [0.53, 0.546474358974359, 0.4835164835164835]\n",
      "Test -  [0.46, 0.4358974358974359, 0.5]\n",
      "\n",
      "Epoch  12\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9431772709083633, 0.8210526315789474]\n",
      "Validation -  [0.48, 0.516025641025641, 0.43478260869565216]\n",
      "Test -  [0.43, 0.4519230769230769, 0.39999999999999997]\n",
      "\n",
      "Epoch  13\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9423769507803121, 0.86]\n",
      "Validation -  [0.6, 0.609375, 0.5652173913043478]\n",
      "Test -  [0.47, 0.4146634615384615, 0.4752475247524752]\n",
      "\n",
      "Epoch  14\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9159663865546218, 0.8712871287128714]\n",
      "Validation -  [0.45, 0.4671474358974359, 0.38202247191011235]\n",
      "Test -  [0.51, 0.4623397435897436, 0.5050505050505051]\n",
      "\n",
      "Epoch  15\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9147659063625451, 0.8]\n",
      "Validation -  [0.51, 0.5240384615384616, 0.44943820224719094]\n",
      "Test -  [0.48, 0.4719551282051282, 0.4583333333333333]\n",
      "\n",
      "Epoch  16\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9335734293717487, 0.8484848484848485]\n",
      "Validation -  [0.49, 0.48597756410256415, 0.43956043956043955]\n",
      "Test -  [0.43, 0.41786858974358976, 0.37362637362637363]\n",
      "\n",
      "Epoch  17\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9227691076430572, 0.8041237113402062]\n",
      "Validation -  [0.52, 0.5436698717948718, 0.4418604651162791]\n",
      "Test -  [0.44, 0.41626602564102566, 0.3636363636363636]\n",
      "\n",
      "Epoch  18\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9443777511004401, 0.8421052631578948]\n",
      "Validation -  [0.58, 0.5564903846153846, 0.5]\n",
      "Test -  [0.48, 0.4639423076923077, 0.4222222222222222]\n",
      "\n",
      "Epoch  19\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9447779111644656, 0.851063829787234]\n",
      "Validation -  [0.47, 0.5072115384615385, 0.3764705882352941]\n",
      "Test -  [0.47, 0.4246794871794872, 0.3908045977011494]\n",
      "\n",
      "Epoch  20\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9379751900760304, 0.8282828282828283]\n",
      "Validation -  [0.48, 0.4419070512820513, 0.3953488372093023]\n",
      "Test -  [0.41, 0.38782051282051283, 0.3655913978494624]\n",
      "\n",
      "Epoch  21\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9423769507803121, 0.8541666666666666]\n",
      "Validation -  [0.55, 0.5608974358974359, 0.430379746835443]\n",
      "Test -  [0.41, 0.34815705128205127, 0.33707865168539325]\n",
      "\n",
      "Epoch  22\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9507803121248499, 0.8349514563106797]\n",
      "Validation -  [0.53, 0.5396634615384615, 0.47191011235955055]\n",
      "Test -  [0.45, 0.37900641025641024, 0.42105263157894735]\n",
      "\n",
      "Epoch  23\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9419767907162866, 0.845360824742268]\n",
      "Validation -  [0.54, 0.501201923076923, 0.46511627906976744]\n",
      "Test -  [0.42, 0.41466346153846156, 0.3829787234042554]\n",
      "\n",
      "Epoch  24\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9339735894357742, 0.86]\n",
      "Validation -  [0.58, 0.565304487179487, 0.5333333333333333]\n",
      "Test -  [0.51, 0.4707532051282051, 0.4948453608247423]\n",
      "\n",
      "Epoch  25\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9475790316126451, 0.84]\n",
      "Validation -  [0.48, 0.46274038461538464, 0.43478260869565216]\n",
      "Test -  [0.44, 0.4451121794871795, 0.4285714285714286]\n",
      "\n",
      "Epoch  26\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9227691076430572, 0.8200000000000001]\n",
      "Validation -  [0.57, 0.5813301282051282, 0.5168539325842697]\n",
      "Test -  [0.44, 0.42788461538461536, 0.4042553191489362]\n",
      "\n",
      "Epoch  27\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9171668667466987, 0.8297872340425532]\n",
      "Validation -  [0.45, 0.48958333333333337, 0.36781609195402293]\n",
      "Test -  [0.5, 0.452724358974359, 0.4791666666666667]\n",
      "\n",
      "Epoch  28\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.78, 0.9283713485394158, 0.7755102040816325]\n",
      "Validation -  [0.6, 0.6374198717948717, 0.5454545454545454]\n",
      "Test -  [0.47, 0.41907051282051283, 0.5137614678899083]\n",
      "\n",
      "Epoch  29\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9223689475790315, 0.8125]\n",
      "Validation -  [0.54, 0.5272435897435898, 0.4888888888888889]\n",
      "Test -  [0.5, 0.44391025641025644, 0.4791666666666667]\n",
      "\n",
      "Epoch  30\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9479791916766707, 0.8247422680412372]\n",
      "Validation -  [0.5, 0.5, 0.4186046511627907]\n",
      "Test -  [0.46, 0.5100160256410257, 0.4489795918367347]\n",
      "\n",
      "Epoch  31\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9403761504601842, 0.8484848484848485]\n",
      "Validation -  [0.44, 0.45352564102564097, 0.4042553191489362]\n",
      "Test -  [0.52, 0.5220352564102564, 0.52]\n",
      "\n",
      "Epoch  32\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9427771108443377, 0.8571428571428571]\n",
      "Validation -  [0.52, 0.4907852564102564, 0.45454545454545453]\n",
      "Test -  [0.43, 0.4314903846153846, 0.4123711340206186]\n",
      "\n",
      "Epoch  33\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9355742296918768, 0.8541666666666666]\n",
      "Validation -  [0.59, 0.5853365384615385, 0.5494505494505495]\n",
      "Test -  [0.51, 0.45913461538461536, 0.5050505050505051]\n",
      "\n",
      "Epoch  34\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9183673469387754, 0.8125]\n",
      "Validation -  [0.5, 0.4499198717948718, 0.4444444444444445]\n",
      "Test -  [0.51, 0.5160256410256411, 0.4842105263157895]\n",
      "\n",
      "Epoch  35\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9219687875150061, 0.8484848484848485]\n",
      "Validation -  [0.52, 0.5352564102564102, 0.45454545454545453]\n",
      "Test -  [0.47, 0.4326923076923077, 0.4421052631578947]\n",
      "\n",
      "Epoch  36\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9359743897559023, 0.8125]\n",
      "Validation -  [0.47, 0.4567307692307693, 0.3764705882352941]\n",
      "Test -  [0.44, 0.4166666666666667, 0.3777777777777778]\n",
      "\n",
      "Epoch  37\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9551820728291317, 0.8541666666666666]\n",
      "Validation -  [0.49, 0.47155448717948717, 0.4000000000000001]\n",
      "Test -  [0.47, 0.4655448717948718, 0.4175824175824176]\n",
      "\n",
      "Epoch  38\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.933173269307723, 0.8210526315789474]\n",
      "Validation -  [0.54, 0.5196314102564104, 0.4390243902439025]\n",
      "Test -  [0.43, 0.4499198717948718, 0.38709677419354843]\n",
      "\n",
      "Epoch  39\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9467787114845938, 0.8737864077669903]\n",
      "Validation -  [0.43, 0.4567307692307692, 0.3294117647058824]\n",
      "Test -  [0.49, 0.46434294871794873, 0.46315789473684216]\n",
      "\n",
      "Epoch  40\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9571828731492598, 0.8387096774193549]\n",
      "Validation -  [0.52, 0.5228365384615384, 0.4418604651162791]\n",
      "Test -  [0.42, 0.41706730769230765, 0.3958333333333333]\n",
      "\n",
      "Epoch  41\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9403761504601841, 0.8125]\n",
      "Validation -  [0.46, 0.4739583333333333, 0.34146341463414637]\n",
      "Test -  [0.45, 0.42107371794871795, 0.40860215053763443]\n",
      "\n",
      "Epoch  42\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.936374549819928, 0.8085106382978724]\n",
      "Validation -  [0.47, 0.502403846153846, 0.3291139240506329]\n",
      "Test -  [0.42, 0.41306089743589747, 0.3958333333333333]\n",
      "\n",
      "Epoch  43\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9179671868747499, 0.845360824742268]\n",
      "Validation -  [0.48, 0.42107371794871795, 0.380952380952381]\n",
      "Test -  [0.45, 0.4419070512820513, 0.36781609195402293]\n",
      "\n",
      "Epoch  44\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9255702280912366, 0.8210526315789474]\n",
      "Validation -  [0.5, 0.5232371794871795, 0.4186046511627907]\n",
      "Test -  [0.47, 0.4595352564102564, 0.4175824175824176]\n",
      "\n",
      "Epoch  45\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9187675070028011, 0.8125]\n",
      "Validation -  [0.53, 0.5176282051282052, 0.43373493975903615]\n",
      "Test -  [0.45, 0.4098557692307693, 0.3956043956043956]\n",
      "\n",
      "Epoch  46\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9575830332132853, 0.8541666666666666]\n",
      "Validation -  [0.6, 0.5496794871794871, 0.5348837209302326]\n",
      "Test -  [0.47, 0.44270833333333337, 0.45360824742268036]\n",
      "\n",
      "Epoch  47\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.912765106042417, 0.8210526315789474]\n",
      "Validation -  [0.55, 0.5280448717948717, 0.5161290322580646]\n",
      "Test -  [0.46, 0.45633012820512825, 0.4489795918367347]\n",
      "\n",
      "Epoch  48\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9463785514205681, 0.8686868686868686]\n",
      "Validation -  [0.53, 0.5436698717948717, 0.47191011235955055]\n",
      "Test -  [0.48, 0.4575320512820513, 0.44680851063829785]\n",
      "\n",
      "Epoch  49\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9187675070028012, 0.8282828282828283]\n",
      "Validation -  [0.54, 0.547275641025641, 0.4772727272727273]\n",
      "Test -  [0.45, 0.407451923076923, 0.40860215053763443]\n",
      "\n",
      "Epoch  50\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.9, 0.9531812725090036, 0.9038461538461539]\n",
      "Validation -  [0.52, 0.485176282051282, 0.48936170212765956]\n",
      "Test -  [0.45, 0.4158653846153846, 0.43298969072164945]\n",
      "\n",
      "Epoch  51\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9291716686674669, 0.8247422680412372]\n",
      "Validation -  [0.53, 0.5060096153846153, 0.5052631578947369]\n",
      "Test -  [0.45, 0.4631410256410256, 0.38202247191011235]\n",
      "\n",
      "Epoch  52\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9467787114845938, 0.8631578947368421]\n",
      "Validation -  [0.5, 0.45472756410256415, 0.4444444444444445]\n",
      "Test -  [0.5, 0.46875, 0.4897959183673469]\n",
      "\n",
      "Epoch  53\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.88, 0.9299719887955182, 0.8775510204081632]\n",
      "Validation -  [0.49, 0.4907852564102564, 0.46315789473684216]\n",
      "Test -  [0.47, 0.46153846153846156, 0.4952380952380952]\n",
      "\n",
      "Epoch  54\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.95078031212485, 0.865979381443299]\n",
      "Validation -  [0.44, 0.44751602564102566, 0.3777777777777778]\n",
      "Test -  [0.51, 0.49318910256410253, 0.4948453608247423]\n",
      "\n",
      "Epoch  55\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.89, 0.9463785514205683, 0.888888888888889]\n",
      "Validation -  [0.53, 0.5288461538461539, 0.4835164835164835]\n",
      "Test -  [0.44, 0.421474358974359, 0.4285714285714286]\n",
      "\n",
      "Epoch  56\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9307723089235693, 0.8085106382978724]\n",
      "Validation -  [0.51, 0.4899839743589744, 0.4842105263157895]\n",
      "Test -  [0.47, 0.421474358974359, 0.4421052631578947]\n",
      "\n",
      "Epoch  57\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9387755102040817, 0.845360824742268]\n",
      "Validation -  [0.52, 0.5276442307692307, 0.45454545454545453]\n",
      "Test -  [0.46, 0.4142628205128205, 0.41304347826086957]\n",
      "\n",
      "Epoch  58\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9151660664265706, 0.8282828282828283]\n",
      "Validation -  [0.53, 0.5128205128205129, 0.4946236559139785]\n",
      "Test -  [0.4, 0.405849358974359, 0.4]\n",
      "\n",
      "Epoch  59\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9415766306522609, 0.865979381443299]\n",
      "Validation -  [0.5, 0.49679487179487175, 0.45652173913043476]\n",
      "Test -  [0.45, 0.44551282051282054, 0.42105263157894735]\n",
      "\n",
      "Epoch  60\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.921968787515006, 0.8421052631578948]\n",
      "Validation -  [0.52, 0.46554487179487175, 0.48936170212765956]\n",
      "Test -  [0.47, 0.43830128205128205, 0.4752475247524752]\n",
      "\n",
      "Epoch  61\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.938375350140056, 0.8631578947368421]\n",
      "Validation -  [0.5, 0.5056089743589745, 0.43181818181818177]\n",
      "Test -  [0.45, 0.422275641025641, 0.40860215053763443]\n",
      "\n",
      "Epoch  62\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.933173269307723, 0.8]\n",
      "Validation -  [0.56, 0.5717147435897437, 0.4883720930232558]\n",
      "Test -  [0.53, 0.4715544871794872, 0.4835164835164835]\n",
      "\n",
      "Epoch  63\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9287715086034414, 0.8172043010752689]\n",
      "Validation -  [0.56, 0.5292467948717948, 0.5]\n",
      "Test -  [0.49, 0.45272435897435903, 0.4742268041237114]\n",
      "\n",
      "Epoch  64\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9431772709083633, 0.8484848484848485]\n",
      "Validation -  [0.52, 0.5264423076923077, 0.4418604651162791]\n",
      "Test -  [0.51, 0.47716346153846156, 0.4731182795698925]\n",
      "\n",
      "Epoch  65\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9295718287314926, 0.8172043010752689]\n",
      "Validation -  [0.49, 0.5552884615384615, 0.33766233766233766]\n",
      "Test -  [0.47, 0.4198717948717949, 0.4421052631578947]\n",
      "\n",
      "Epoch  66\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9279711884753902, 0.8163265306122448]\n",
      "Validation -  [0.53, 0.48798076923076933, 0.43373493975903615]\n",
      "Test -  [0.48, 0.3770032051282051, 0.4222222222222222]\n",
      "\n",
      "Epoch  67\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9143657462985193, 0.7916666666666666]\n",
      "Validation -  [0.51, 0.562900641025641, 0.42352941176470593]\n",
      "Test -  [0.45, 0.4274839743589744, 0.40860215053763443]\n",
      "\n",
      "Epoch  68\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9107643057222888, 0.8]\n",
      "Validation -  [0.53, 0.5360576923076922, 0.47191011235955055]\n",
      "Test -  [0.45, 0.4743589743589744, 0.36781609195402293]\n",
      "\n",
      "Epoch  69\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9227691076430572, 0.8247422680412372]\n",
      "Validation -  [0.46, 0.47315705128205127, 0.372093023255814]\n",
      "Test -  [0.43, 0.40224358974358976, 0.38709677419354843]\n",
      "\n",
      "Epoch  70\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9323729491796718, 0.8210526315789474]\n",
      "Validation -  [0.53, 0.5208333333333334, 0.44705882352941173]\n",
      "Test -  [0.49, 0.5016025641025641, 0.45161290322580644]\n",
      "\n",
      "Epoch  71\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9243697478991596, 0.8]\n",
      "Validation -  [0.47, 0.4855769230769231, 0.40449438202247195]\n",
      "Test -  [0.46, 0.4967948717948718, 0.4807692307692308]\n",
      "\n",
      "Epoch  72\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9367747098839536, 0.8085106382978724]\n",
      "Validation -  [0.51, 0.49278846153846156, 0.44943820224719094]\n",
      "Test -  [0.48, 0.4655448717948718, 0.4090909090909091]\n",
      "\n",
      "Epoch  73\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9447779111644657, 0.8571428571428571]\n",
      "Validation -  [0.53, 0.561698717948718, 0.47191011235955055]\n",
      "Test -  [0.46, 0.4515224358974359, 0.425531914893617]\n",
      "\n",
      "Epoch  74\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9559823929571829, 0.8602150537634408]\n",
      "Validation -  [0.57, 0.5180288461538463, 0.4941176470588235]\n",
      "Test -  [0.47, 0.46434294871794873, 0.4301075268817204]\n",
      "\n",
      "Epoch  75\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9267707082833133, 0.7959183673469387]\n",
      "Validation -  [0.52, 0.546073717948718, 0.4418604651162791]\n",
      "Test -  [0.46, 0.39863782051282054, 0.372093023255814]\n",
      "\n",
      "Epoch  76\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.938375350140056, 0.8297872340425532]\n",
      "Validation -  [0.56, 0.5685096153846153, 0.45]\n",
      "Test -  [0.43, 0.4106570512820513, 0.38709677419354843]\n",
      "\n",
      "Epoch  77\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9431772709083633, 0.845360824742268]\n",
      "Validation -  [0.47, 0.45833333333333337, 0.3908045977011494]\n",
      "Test -  [0.47, 0.4186698717948718, 0.4175824175824176]\n",
      "\n",
      "Epoch  78\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9415766306522609, 0.8297872340425532]\n",
      "Validation -  [0.52, 0.5196314102564102, 0.42857142857142855]\n",
      "Test -  [0.45, 0.41266025641025644, 0.36781609195402293]\n",
      "\n",
      "Epoch  79\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9331732693077232, 0.8247422680412372]\n",
      "Validation -  [0.45, 0.4831730769230769, 0.3529411764705882]\n",
      "Test -  [0.5, 0.43309294871794873, 0.43181818181818177]\n",
      "\n",
      "Epoch  80\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9223689475790315, 0.8333333333333334]\n",
      "Validation -  [0.56, 0.5344551282051282, 0.4761904761904762]\n",
      "Test -  [0.46, 0.48677884615384615, 0.34146341463414637]\n",
      "\n",
      "Epoch  81\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9615846338535414, 0.865979381443299]\n",
      "Validation -  [0.54, 0.5853365384615384, 0.45238095238095233]\n",
      "Test -  [0.44, 0.4046474358974359, 0.3913043478260869]\n",
      "\n",
      "Epoch  82\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.923969587835134, 0.8125]\n",
      "Validation -  [0.5, 0.5212339743589743, 0.4680851063829787]\n",
      "Test -  [0.44, 0.4511217948717949, 0.4042553191489362]\n",
      "\n",
      "Epoch  83\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9123649459783912, 0.8367346938775511]\n",
      "Validation -  [0.54, 0.532051282051282, 0.4772727272727273]\n",
      "Test -  [0.46, 0.4763621794871795, 0.38636363636363635]\n",
      "\n",
      "Epoch  84\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9127651060424169, 0.8282828282828283]\n",
      "Validation -  [0.47, 0.46634615384615385, 0.40449438202247195]\n",
      "Test -  [0.39, 0.4078525641025641, 0.35789473684210527]\n",
      "\n",
      "Epoch  85\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9247699079631853, 0.8085106382978724]\n",
      "Validation -  [0.52, 0.5044070512820513, 0.4782608695652174]\n",
      "Test -  [0.48, 0.4639423076923077, 0.48000000000000004]\n",
      "\n",
      "Epoch  86\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9235694277711084, 0.8041237113402062]\n",
      "Validation -  [0.6, 0.579326923076923, 0.5454545454545454]\n",
      "Test -  [0.49, 0.4891826923076923, 0.48484848484848486]\n",
      "\n",
      "Epoch  87\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9387755102040816, 0.8297872340425532]\n",
      "Validation -  [0.5, 0.47676282051282054, 0.4791666666666667]\n",
      "Test -  [0.43, 0.437099358974359, 0.42424242424242425]\n",
      "\n",
      "Epoch  88\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.943577430972389, 0.865979381443299]\n",
      "Validation -  [0.45, 0.5144230769230769, 0.40860215053763443]\n",
      "Test -  [0.53, 0.47475961538461536, 0.5154639175257733]\n",
      "\n",
      "Epoch  89\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.916766706682673, 0.8367346938775511]\n",
      "Validation -  [0.49, 0.5104166666666666, 0.42696629213483145]\n",
      "Test -  [0.45, 0.405849358974359, 0.3956043956043956]\n",
      "\n",
      "Epoch  90\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9163665466186475, 0.7912087912087913]\n",
      "Validation -  [0.5, 0.45913461538461536, 0.4444444444444445]\n",
      "Test -  [0.5, 0.49399038461538464, 0.4444444444444445]\n",
      "\n",
      "Epoch  91\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9391756702681072, 0.8247422680412372]\n",
      "Validation -  [0.56, 0.5372596153846153, 0.5111111111111111]\n",
      "Test -  [0.47, 0.4623397435897436, 0.4301075268817204]\n",
      "\n",
      "Epoch  92\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9303721488595438, 0.8210526315789474]\n",
      "Validation -  [0.51, 0.49599358974358976, 0.4615384615384615]\n",
      "Test -  [0.38, 0.37780448717948717, 0.2619047619047619]\n",
      "\n",
      "Epoch  93\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9235694277711085, 0.8260869565217392]\n",
      "Validation -  [0.5, 0.5296474358974359, 0.43181818181818177]\n",
      "Test -  [0.5, 0.41907051282051283, 0.43181818181818177]\n",
      "\n",
      "Epoch  94\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9367747098839536, 0.8085106382978724]\n",
      "Validation -  [0.56, 0.5749198717948717, 0.4761904761904762]\n",
      "Test -  [0.46, 0.44551282051282054, 0.372093023255814]\n",
      "\n",
      "Epoch  95\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9567827130852342, 0.8602150537634408]\n",
      "Validation -  [0.51, 0.4911858974358974, 0.3950617283950617]\n",
      "Test -  [0.43, 0.4082532051282051, 0.37362637362637363]\n",
      "\n",
      "Epoch  96\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9347739095638254, 0.8541666666666666]\n",
      "Validation -  [0.54, 0.5144230769230769, 0.39473684210526316]\n",
      "Test -  [0.42, 0.3729967948717949, 0.3095238095238095]\n",
      "\n",
      "Epoch  97\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9359743897559023, 0.8297872340425532]\n",
      "Validation -  [0.49, 0.49519230769230765, 0.38554216867469876]\n",
      "Test -  [0.44, 0.4346955128205128, 0.3488372093023256]\n",
      "\n",
      "Epoch  98\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9463785514205681, 0.8541666666666666]\n",
      "Validation -  [0.5, 0.48357371794871795, 0.39024390243902435]\n",
      "Test -  [0.48, 0.46314102564102566, 0.44680851063829785]\n",
      "\n",
      "Epoch  99\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9295718287314927, 0.8484848484848485]\n",
      "Validation -  [0.53, 0.48357371794871795, 0.47191011235955055]\n",
      "Test -  [0.48, 0.421875, 0.4583333333333333]\n",
      "\n",
      "Epoch  100\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.89, 0.9623849539815926, 0.888888888888889]\n",
      "Validation -  [0.57, 0.5292467948717948, 0.4941176470588235]\n",
      "Test -  [0.43, 0.4903846153846154, 0.4123711340206186]\n",
      "\n",
      "Epoch  101\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9063625450180072, 0.8]\n",
      "Validation -  [0.59, 0.5608974358974359, 0.5060240963855421]\n",
      "Test -  [0.44, 0.4639423076923077, 0.4166666666666667]\n",
      "\n",
      "Epoch  102\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9411764705882353, 0.8333333333333334]\n",
      "Validation -  [0.51, 0.5396634615384616, 0.44943820224719094]\n",
      "Test -  [0.44, 0.4014423076923077, 0.4285714285714286]\n",
      "\n",
      "Epoch  103\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9471788715486195, 0.8541666666666666]\n",
      "Validation -  [0.45, 0.4707532051282051, 0.42105263157894735]\n",
      "Test -  [0.41, 0.42908653846153855, 0.3516483516483517]\n",
      "\n",
      "Epoch  104\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9243697478991597, 0.8484848484848485]\n",
      "Validation -  [0.54, 0.4983974358974359, 0.46511627906976744]\n",
      "Test -  [0.48, 0.4795673076923077, 0.48000000000000004]\n",
      "\n",
      "Epoch  105\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9447779111644657, 0.8297872340425532]\n",
      "Validation -  [0.53, 0.5484775641025641, 0.4835164835164835]\n",
      "Test -  [0.44, 0.40344551282051283, 0.3777777777777778]\n",
      "\n",
      "Epoch  106\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9419767907162865, 0.8571428571428571]\n",
      "Validation -  [0.5, 0.4783653846153846, 0.4444444444444445]\n",
      "Test -  [0.44, 0.4354967948717949, 0.43999999999999995]\n",
      "\n",
      "Epoch  107\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9295718287314926, 0.8163265306122448]\n",
      "Validation -  [0.54, 0.5528846153846154, 0.5]\n",
      "Test -  [0.45, 0.42427884615384615, 0.4554455445544555]\n",
      "\n",
      "Epoch  108\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9319727891156463, 0.8333333333333334]\n",
      "Validation -  [0.61, 0.6069711538461539, 0.5806451612903225]\n",
      "Test -  [0.44, 0.4162660256410256, 0.3913043478260869]\n",
      "\n",
      "Epoch  109\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9563825530212086, 0.8484848484848485]\n",
      "Validation -  [0.47, 0.4815705128205128, 0.40449438202247195]\n",
      "Test -  [0.47, 0.4923878205128205, 0.45360824742268036]\n",
      "\n",
      "Epoch  110\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9423769507803121, 0.8367346938775511]\n",
      "Validation -  [0.6, 0.5428685897435898, 0.5121951219512195]\n",
      "Test -  [0.45, 0.38221153846153844, 0.3956043956043956]\n",
      "\n",
      "Epoch  111\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9447779111644657, 0.8297872340425532]\n",
      "Validation -  [0.49, 0.5240384615384616, 0.42696629213483145]\n",
      "Test -  [0.5, 0.4807692307692308, 0.4444444444444445]\n",
      "\n",
      "Epoch  112\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9295718287314926, 0.8247422680412372]\n",
      "Validation -  [0.52, 0.5364583333333333, 0.4418604651162791]\n",
      "Test -  [0.44, 0.437099358974359, 0.4166666666666667]\n",
      "\n",
      "Epoch  113\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9391756702681072, 0.8541666666666666]\n",
      "Validation -  [0.59, 0.564903846153846, 0.5287356321839081]\n",
      "Test -  [0.43, 0.4314903846153846, 0.38709677419354843]\n",
      "\n",
      "Epoch  114\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9467787114845938, 0.865979381443299]\n",
      "Validation -  [0.54, 0.5396634615384616, 0.4390243902439025]\n",
      "Test -  [0.45, 0.47115384615384615, 0.3956043956043956]\n",
      "\n",
      "Epoch  115\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9403761504601841, 0.8421052631578948]\n",
      "Validation -  [0.54, 0.5264423076923076, 0.46511627906976744]\n",
      "Test -  [0.42, 0.3842147435897436, 0.4081632653061225]\n",
      "\n",
      "Epoch  116\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9499799919967987, 0.8541666666666666]\n",
      "Validation -  [0.5, 0.5124198717948718, 0.375]\n",
      "Test -  [0.49, 0.48197115384615385, 0.45161290322580644]\n",
      "\n",
      "Epoch  117\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.88, 0.9495798319327731, 0.8775510204081632]\n",
      "Validation -  [0.59, 0.5504807692307692, 0.5393258426966292]\n",
      "Test -  [0.51, 0.4639423076923077, 0.4842105263157895]\n",
      "\n",
      "Epoch  118\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.91796718687475, 0.84]\n",
      "Validation -  [0.55, 0.5560897435897436, 0.4827586206896552]\n",
      "Test -  [0.49, 0.453525641025641, 0.46315789473684216]\n",
      "\n",
      "Epoch  119\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9391756702681072, 0.8367346938775511]\n",
      "Validation -  [0.49, 0.4963942307692308, 0.45161290322580644]\n",
      "Test -  [0.48, 0.4250801282051282, 0.46938775510204084]\n",
      "\n",
      "Epoch  120\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9391756702681072, 0.84]\n",
      "Validation -  [0.51, 0.4911858974358974, 0.44943820224719094]\n",
      "Test -  [0.52, 0.4659455128205128, 0.5384615384615384]\n",
      "\n",
      "Epoch  121\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9447779111644657, 0.84]\n",
      "Validation -  [0.55, 0.577724358974359, 0.5054945054945056]\n",
      "Test -  [0.48, 0.42868589743589747, 0.44680851063829785]\n",
      "\n",
      "Epoch  122\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9399759903961585, 0.8484848484848485]\n",
      "Validation -  [0.54, 0.5408653846153846, 0.5208333333333334]\n",
      "Test -  [0.4, 0.4643429487179487, 0.4230769230769231]\n",
      "\n",
      "Epoch  123\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9375750300120048, 0.86]\n",
      "Validation -  [0.49, 0.4823717948717949, 0.4742268041237114]\n",
      "Test -  [0.46, 0.4423076923076923, 0.45999999999999996]\n",
      "\n",
      "Epoch  124\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9463785514205681, 0.8514851485148515]\n",
      "Validation -  [0.52, 0.5588942307692307, 0.48936170212765956]\n",
      "Test -  [0.48, 0.4547275641025641, 0.48000000000000004]\n",
      "\n",
      "Epoch  125\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9083633453381352, 0.8118811881188118]\n",
      "Validation -  [0.49, 0.5280448717948717, 0.4742268041237114]\n",
      "Test -  [0.4, 0.3774038461538461, 0.3877551020408163]\n",
      "\n",
      "Epoch  126\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9375750300120048, 0.8163265306122448]\n",
      "Validation -  [0.49, 0.4599358974358974, 0.41379310344827586]\n",
      "Test -  [0.42, 0.41266025641025644, 0.4081632653061225]\n",
      "\n",
      "Epoch  127\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9367747098839536, 0.865979381443299]\n",
      "Validation -  [0.49, 0.5080128205128205, 0.45161290322580644]\n",
      "Test -  [0.42, 0.4623397435897436, 0.4313725490196078]\n",
      "\n",
      "Epoch  128\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9371748699479792, 0.845360824742268]\n",
      "Validation -  [0.52, 0.4911858974358974, 0.4418604651162791]\n",
      "Test -  [0.47, 0.43108974358974356, 0.4301075268817204]\n",
      "\n",
      "Epoch  129\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.929171668667467, 0.8297872340425532]\n",
      "Validation -  [0.49, 0.5080128205128205, 0.4000000000000001]\n",
      "Test -  [0.51, 0.4995993589743589, 0.4842105263157895]\n",
      "\n",
      "Epoch  130\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.89, 0.959983993597439, 0.888888888888889]\n",
      "Validation -  [0.5, 0.4979967948717949, 0.43181818181818177]\n",
      "Test -  [0.46, 0.42828525641025644, 0.4489795918367347]\n",
      "\n",
      "Epoch  131\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9315726290516206, 0.8602150537634408]\n",
      "Validation -  [0.53, 0.5552884615384616, 0.4597701149425287]\n",
      "Test -  [0.47, 0.4375, 0.4175824175824176]\n",
      "\n",
      "Epoch  132\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9375750300120048, 0.8]\n",
      "Validation -  [0.52, 0.5216346153846154, 0.4782608695652174]\n",
      "Test -  [0.46, 0.45873397435897434, 0.39999999999999997]\n",
      "\n",
      "Epoch  133\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9431772709083635, 0.86]\n",
      "Validation -  [0.52, 0.5492788461538461, 0.45454545454545453]\n",
      "Test -  [0.45, 0.4559294871794872, 0.4761904761904762]\n",
      "\n",
      "Epoch  134\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9623849539815926, 0.8421052631578948]\n",
      "Validation -  [0.49, 0.47836538461538464, 0.41379310344827586]\n",
      "Test -  [0.49, 0.4735576923076923, 0.48484848484848486]\n",
      "\n",
      "Epoch  135\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9311724689875951, 0.8172043010752689]\n",
      "Validation -  [0.45, 0.4415064102564103, 0.38202247191011235]\n",
      "Test -  [0.49, 0.47115384615384615, 0.4742268041237114]\n",
      "\n",
      "Epoch  136\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.936374549819928, 0.8210526315789474]\n",
      "Validation -  [0.49, 0.48677884615384615, 0.3703703703703703]\n",
      "Test -  [0.45, 0.44511217948717946, 0.40860215053763443]\n",
      "\n",
      "Epoch  137\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9543817527010804, 0.8514851485148515]\n",
      "Validation -  [0.53, 0.4811698717948718, 0.44705882352941173]\n",
      "Test -  [0.43, 0.4146634615384615, 0.35955056179775274]\n",
      "\n",
      "Epoch  138\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9487795118047219, 0.845360824742268]\n",
      "Validation -  [0.55, 0.5060096153846154, 0.4444444444444444]\n",
      "Test -  [0.49, 0.4931891025641026, 0.41379310344827586]\n",
      "\n",
      "Epoch  139\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.88, 0.9523809523809523, 0.8775510204081632]\n",
      "Validation -  [0.52, 0.5388621794871794, 0.45454545454545453]\n",
      "Test -  [0.44, 0.3926282051282052, 0.3488372093023256]\n",
      "\n",
      "Epoch  140\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9379751900760305, 0.8260869565217392]\n",
      "Validation -  [0.48, 0.5160256410256411, 0.3953488372093023]\n",
      "Test -  [0.45, 0.5356570512820513, 0.3529411764705882]\n",
      "\n",
      "Epoch  141\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9391756702681073, 0.8421052631578948]\n",
      "Validation -  [0.54, 0.5244391025641025, 0.46511627906976744]\n",
      "Test -  [0.45, 0.4739583333333333, 0.38202247191011235]\n",
      "\n",
      "Epoch  142\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.929171668667467, 0.8247422680412372]\n",
      "Validation -  [0.47, 0.49238782051282054, 0.3291139240506329]\n",
      "Test -  [0.44, 0.42067307692307687, 0.3333333333333333]\n",
      "\n",
      "Epoch  143\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9311724689875951, 0.8367346938775511]\n",
      "Validation -  [0.5, 0.47876602564102566, 0.43181818181818177]\n",
      "Test -  [0.43, 0.41586538461538464, 0.2962962962962963]\n",
      "\n",
      "Epoch  144\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9411764705882353, 0.8571428571428571]\n",
      "Validation -  [0.49, 0.4707532051282051, 0.38554216867469876]\n",
      "Test -  [0.47, 0.4707532051282052, 0.4175824175824176]\n",
      "\n",
      "Epoch  145\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9531812725090035, 0.8631578947368421]\n",
      "Validation -  [0.46, 0.5072115384615384, 0.35714285714285715]\n",
      "Test -  [0.41, 0.40224358974358976, 0.3917525773195876]\n",
      "\n",
      "Epoch  146\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.938375350140056, 0.8541666666666666]\n",
      "Validation -  [0.58, 0.5420673076923077, 0.5531914893617021]\n",
      "Test -  [0.48, 0.4194711538461538, 0.44680851063829785]\n",
      "\n",
      "Epoch  147\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9451780712284914, 0.8172043010752689]\n",
      "Validation -  [0.52, 0.49118589743589747, 0.4418604651162791]\n",
      "Test -  [0.46, 0.45072115384615385, 0.38636363636363635]\n",
      "\n",
      "Epoch  148\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9095638255302121, 0.7789473684210527]\n",
      "Validation -  [0.52, 0.5564903846153846, 0.4666666666666667]\n",
      "Test -  [0.43, 0.41306089743589747, 0.37362637362637363]\n",
      "\n",
      "Epoch  149\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9447779111644657, 0.8297872340425532]\n",
      "Validation -  [0.58, 0.610176282051282, 0.5116279069767442]\n",
      "Test -  [0.48, 0.4435096153846154, 0.4583333333333333]\n",
      "\n",
      "Epoch  150\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9371748699479792, 0.8333333333333334]\n",
      "Validation -  [0.48, 0.5112179487179488, 0.3953488372093023]\n",
      "Test -  [0.43, 0.4703525641025641, 0.38709677419354843]\n",
      "\n",
      "Epoch  151\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9419767907162865, 0.8367346938775511]\n",
      "Validation -  [0.5, 0.5236378205128206, 0.4047619047619048]\n",
      "Test -  [0.46, 0.4727564102564103, 0.4489795918367347]\n",
      "\n",
      "Epoch  152\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9375750300120047, 0.8085106382978724]\n",
      "Validation -  [0.56, 0.5552884615384616, 0.4883720930232558]\n",
      "Test -  [0.48, 0.41185897435897445, 0.4222222222222222]\n",
      "\n",
      "Epoch  153\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9231692677070827, 0.8247422680412372]\n",
      "Validation -  [0.52, 0.5048076923076923, 0.45454545454545453]\n",
      "Test -  [0.43, 0.4158653846153847, 0.38709677419354843]\n",
      "\n",
      "Epoch  154\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.954781912765106, 0.8387096774193549]\n",
      "Validation -  [0.54, 0.514823717948718, 0.4772727272727273]\n",
      "Test -  [0.47, 0.469551282051282, 0.4175824175824176]\n",
      "\n",
      "Epoch  155\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.76, 0.9239695878351342, 0.7446808510638299]\n",
      "Validation -  [0.55, 0.53125, 0.5161290322580646]\n",
      "Test -  [0.43, 0.41185897435897434, 0.38709677419354843]\n",
      "\n",
      "Epoch  156\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9243697478991597, 0.8247422680412372]\n",
      "Validation -  [0.46, 0.4751602564102564, 0.39999999999999997]\n",
      "Test -  [0.44, 0.41466346153846156, 0.4042553191489362]\n",
      "\n",
      "Epoch  157\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9319727891156462, 0.8041237113402062]\n",
      "Validation -  [0.56, 0.5368589743589743, 0.5416666666666666]\n",
      "Test -  [0.4, 0.4046474358974359, 0.375]\n",
      "\n",
      "Epoch  158\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9351740696278511, 0.8712871287128714]\n",
      "Validation -  [0.49, 0.4779647435897436, 0.4000000000000001]\n",
      "Test -  [0.5, 0.4639423076923077, 0.4791666666666667]\n",
      "\n",
      "Epoch  159\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9423769507803121, 0.8210526315789474]\n",
      "Validation -  [0.5, 0.5252403846153846, 0.4186046511627907]\n",
      "Test -  [0.32, 0.3806089743589744, 0.2608695652173913]\n",
      "\n",
      "Epoch  160\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9051620648259303, 0.8163265306122448]\n",
      "Validation -  [0.54, 0.5252403846153846, 0.5106382978723404]\n",
      "Test -  [0.46, 0.45432692307692313, 0.372093023255814]\n",
      "\n",
      "Epoch  161\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9467787114845939, 0.8333333333333334]\n",
      "Validation -  [0.45, 0.5268429487179487, 0.38202247191011235]\n",
      "Test -  [0.5, 0.49719551282051283, 0.45652173913043476]\n",
      "\n",
      "Epoch  162\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9243697478991597, 0.8085106382978724]\n",
      "Validation -  [0.55, 0.5360576923076923, 0.4827586206896552]\n",
      "Test -  [0.45, 0.452724358974359, 0.42105263157894735]\n",
      "\n",
      "Epoch  163\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.916766706682673, 0.8080808080808081]\n",
      "Validation -  [0.51, 0.5136217948717949, 0.4731182795698925]\n",
      "Test -  [0.45, 0.41786858974358976, 0.42105263157894735]\n",
      "\n",
      "Epoch  164\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.936374549819928, 0.8043478260869564]\n",
      "Validation -  [0.47, 0.4423076923076923, 0.40449438202247195]\n",
      "Test -  [0.49, 0.4583333333333333, 0.48484848484848486]\n",
      "\n",
      "Epoch  165\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9499799919967986, 0.84]\n",
      "Validation -  [0.57, 0.5528846153846154, 0.5376344086021506]\n",
      "Test -  [0.45, 0.4387019230769231, 0.4444444444444445]\n",
      "\n",
      "Epoch  166\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9355742296918768, 0.8387096774193549]\n",
      "Validation -  [0.55, 0.5600961538461539, 0.4827586206896552]\n",
      "Test -  [0.44, 0.4082532051282052, 0.4166666666666667]\n",
      "\n",
      "Epoch  167\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9039615846338536, 0.7916666666666666]\n",
      "Validation -  [0.46, 0.4747596153846154, 0.39999999999999997]\n",
      "Test -  [0.41, 0.390625, 0.37894736842105264]\n",
      "\n",
      "Epoch  168\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9383753501400561, 0.8235294117647058]\n",
      "Validation -  [0.47, 0.484375, 0.3908045977011494]\n",
      "Test -  [0.41, 0.4166666666666667, 0.3917525773195876]\n",
      "\n",
      "Epoch  169\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9247699079631853, 0.845360824742268]\n",
      "Validation -  [0.51, 0.4803685897435898, 0.4842105263157895]\n",
      "Test -  [0.4, 0.34775641025641024, 0.375]\n",
      "\n",
      "Epoch  170\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9379751900760305, 0.8210526315789474]\n",
      "Validation -  [0.56, 0.5216346153846153, 0.5416666666666666]\n",
      "Test -  [0.47, 0.42708333333333337, 0.4421052631578947]\n",
      "\n",
      "Epoch  171\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9375750300120047, 0.8316831683168315]\n",
      "Validation -  [0.51, 0.5388621794871795, 0.4615384615384615]\n",
      "Test -  [0.46, 0.45432692307692313, 0.41304347826086957]\n",
      "\n",
      "Epoch  172\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9539815926370548, 0.8333333333333334]\n",
      "Validation -  [0.55, 0.5484775641025641, 0.5161290322580646]\n",
      "Test -  [0.49, 0.43309294871794873, 0.5048543689320388]\n",
      "\n",
      "Epoch  173\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9231692677070829, 0.826923076923077]\n",
      "Validation -  [0.51, 0.46073717948717946, 0.43678160919540227]\n",
      "Test -  [0.47, 0.4503205128205129, 0.4421052631578947]\n",
      "\n",
      "Epoch  174\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.9, 0.9491796718687475, 0.9]\n",
      "Validation -  [0.51, 0.5092147435897436, 0.4731182795698925]\n",
      "Test -  [0.47, 0.46274038461538464, 0.45360824742268036]\n",
      "\n",
      "Epoch  175\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9111644657863146, 0.8125]\n",
      "Validation -  [0.59, 0.5753205128205129, 0.577319587628866]\n",
      "Test -  [0.4, 0.4202724358974359, 0.375]\n",
      "\n",
      "Epoch  176\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9419767907162865, 0.8431372549019607]\n",
      "Validation -  [0.54, 0.5088141025641025, 0.5]\n",
      "Test -  [0.5, 0.46634615384615385, 0.45652173913043476]\n",
      "\n",
      "Epoch  177\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9479791916766707, 0.8627450980392157]\n",
      "Validation -  [0.5, 0.5248397435897436, 0.45652173913043476]\n",
      "Test -  [0.44, 0.468349358974359, 0.4166666666666667]\n",
      "\n",
      "Epoch  178\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9559823929571829, 0.8571428571428571]\n",
      "Validation -  [0.55, 0.5937499999999999, 0.5054945054945056]\n",
      "Test -  [0.45, 0.4322916666666667, 0.4444444444444445]\n",
      "\n",
      "Epoch  179\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9375750300120048, 0.8484848484848485]\n",
      "Validation -  [0.51, 0.5272435897435898, 0.4842105263157895]\n",
      "Test -  [0.44, 0.4074519230769231, 0.4042553191489362]\n",
      "\n",
      "Epoch  180\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9299719887955181, 0.8367346938775511]\n",
      "Validation -  [0.5, 0.46314102564102566, 0.4444444444444445]\n",
      "Test -  [0.45, 0.47836538461538464, 0.42105263157894735]\n",
      "\n",
      "Epoch  181\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9367747098839535, 0.8125]\n",
      "Validation -  [0.59, 0.5689102564102563, 0.5591397849462364]\n",
      "Test -  [0.4, 0.4186698717948718, 0.3333333333333333]\n",
      "\n",
      "Epoch  182\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9595838335334133, 0.8712871287128714]\n",
      "Validation -  [0.46, 0.499599358974359, 0.38636363636363635]\n",
      "Test -  [0.48, 0.4555288461538462, 0.46938775510204084]\n",
      "\n",
      "Epoch  183\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9275710284113645, 0.8367346938775511]\n",
      "Validation -  [0.43, 0.4431089743589743, 0.35955056179775274]\n",
      "Test -  [0.43, 0.437099358974359, 0.38709677419354843]\n",
      "\n",
      "Epoch  184\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9447779111644657, 0.8282828282828283]\n",
      "Validation -  [0.55, 0.5657051282051282, 0.5054945054945056]\n",
      "Test -  [0.47, 0.4719551282051282, 0.4175824175824176]\n",
      "\n",
      "Epoch  185\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9111644657863145, 0.8235294117647058]\n",
      "Validation -  [0.51, 0.515625, 0.4615384615384615]\n",
      "Test -  [0.42, 0.3669871794871795, 0.35555555555555557]\n",
      "\n",
      "Epoch  186\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9439775910364145, 0.8686868686868686]\n",
      "Validation -  [0.48, 0.4551282051282051, 0.4222222222222222]\n",
      "Test -  [0.44, 0.4411057692307693, 0.4042553191489362]\n",
      "\n",
      "Epoch  187\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9075630252100839, 0.7741935483870968]\n",
      "Validation -  [0.59, 0.546073717948718, 0.5393258426966292]\n",
      "Test -  [0.43, 0.436298076923077, 0.43564356435643564]\n",
      "\n",
      "Epoch  188\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9315726290516206, 0.8333333333333334]\n",
      "Validation -  [0.49, 0.5144230769230769, 0.45161290322580644]\n",
      "Test -  [0.42, 0.391426282051282, 0.3958333333333333]\n",
      "\n",
      "Epoch  189\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9315726290516206, 0.8571428571428571]\n",
      "Validation -  [0.5, 0.4863782051282051, 0.43181818181818177]\n",
      "Test -  [0.45, 0.46634615384615385, 0.42105263157894735]\n",
      "\n",
      "Epoch  190\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9479791916766707, 0.8041237113402062]\n",
      "Validation -  [0.49, 0.4575320512820513, 0.41379310344827586]\n",
      "Test -  [0.47, 0.48998397435897434, 0.4175824175824176]\n",
      "\n",
      "Epoch  191\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.88, 0.9491796718687475, 0.8749999999999999]\n",
      "Validation -  [0.57, 0.5320512820512819, 0.4941176470588235]\n",
      "Test -  [0.48, 0.47275641025641024, 0.43478260869565216]\n",
      "\n",
      "Epoch  192\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9499799919967987, 0.8484848484848485]\n",
      "Validation -  [0.51, 0.5344551282051282, 0.44943820224719094]\n",
      "Test -  [0.47, 0.48357371794871795, 0.45360824742268036]\n",
      "\n",
      "Epoch  193\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9539815926370548, 0.8421052631578948]\n",
      "Validation -  [0.49, 0.49959935897435903, 0.4000000000000001]\n",
      "Test -  [0.48, 0.4611378205128205, 0.44680851063829785]\n",
      "\n",
      "Epoch  194\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9523809523809523, 0.851063829787234]\n",
      "Validation -  [0.53, 0.5372596153846153, 0.4597701149425287]\n",
      "Test -  [0.46, 0.4487179487179487, 0.39999999999999997]\n",
      "\n",
      "Epoch  195\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9411764705882353, 0.7916666666666666]\n",
      "Validation -  [0.5, 0.5200320512820512, 0.4186046511627907]\n",
      "Test -  [0.39, 0.37900641025641024, 0.34408602150537637]\n",
      "\n",
      "Epoch  196\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9259703881552621, 0.8333333333333334]\n",
      "Validation -  [0.59, 0.5713141025641025, 0.4938271604938272]\n",
      "Test -  [0.44, 0.45552884615384615, 0.4042553191489362]\n",
      "\n",
      "Epoch  197\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.88, 0.952781112444978, 0.8799999999999999]\n",
      "Validation -  [0.54, 0.4931891025641026, 0.46511627906976744]\n",
      "Test -  [0.49, 0.4515224358974359, 0.45161290322580644]\n",
      "\n",
      "Epoch  198\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9507803121248499, 0.8387096774193549]\n",
      "Validation -  [0.52, 0.5056089743589743, 0.4418604651162791]\n",
      "Test -  [0.42, 0.43509615384615385, 0.3409090909090909]\n",
      "\n",
      "Epoch  199\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.929171668667467, 0.8541666666666666]\n",
      "Validation -  [0.52, 0.499599358974359, 0.4418604651162791]\n",
      "Test -  [0.48, 0.46955128205128205, 0.4583333333333333]\n",
      "\n",
      "Epoch  200\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.943577430972389, 0.851063829787234]\n",
      "Validation -  [0.53, 0.4895833333333333, 0.44705882352941173]\n",
      "Test -  [0.51, 0.4539262820512821, 0.5148514851485149]\n",
      "\n",
      "Epoch  201\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9551820728291316, 0.8333333333333334]\n",
      "Validation -  [0.55, 0.5328525641025641, 0.4444444444444444]\n",
      "Test -  [0.44, 0.4178685897435897, 0.3777777777777778]\n",
      "\n",
      "Epoch  202\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9459783913565425, 0.8333333333333334]\n",
      "Validation -  [0.58, 0.49719551282051283, 0.5227272727272727]\n",
      "Test -  [0.45, 0.45072115384615385, 0.3956043956043956]\n",
      "\n",
      "Epoch  203\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9391756702681073, 0.8541666666666666]\n",
      "Validation -  [0.49, 0.5236378205128205, 0.35443037974683544]\n",
      "Test -  [0.47, 0.4270833333333333, 0.4175824175824176]\n",
      "\n",
      "Epoch  204\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9427771108443377, 0.8333333333333334]\n",
      "Validation -  [0.51, 0.5268429487179487, 0.42352941176470593]\n",
      "Test -  [0.43, 0.3998397435897436, 0.3294117647058824]\n",
      "\n",
      "Epoch  205\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9487795118047219, 0.8421052631578948]\n",
      "Validation -  [0.54, 0.5112179487179487, 0.45238095238095233]\n",
      "Test -  [0.49, 0.45112179487179493, 0.41379310344827586]\n",
      "\n",
      "Epoch  206\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9431772709083633, 0.7741935483870968]\n",
      "Validation -  [0.54, 0.5104166666666667, 0.4888888888888889]\n",
      "Test -  [0.46, 0.45913461538461536, 0.425531914893617]\n",
      "\n",
      "Epoch  207\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9355742296918768, 0.865979381443299]\n",
      "Validation -  [0.58, 0.592948717948718, 0.5116279069767442]\n",
      "Test -  [0.55, 0.5164262820512819, 0.5161290322580646]\n",
      "\n",
      "Epoch  208\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9391756702681071, 0.8210526315789474]\n",
      "Validation -  [0.53, 0.5532852564102564, 0.47191011235955055]\n",
      "Test -  [0.45, 0.4166666666666667, 0.40860215053763443]\n",
      "\n",
      "Epoch  209\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9403761504601841, 0.8]\n",
      "Validation -  [0.53, 0.531650641025641, 0.47191011235955055]\n",
      "Test -  [0.52, 0.48557692307692313, 0.4418604651162791]\n",
      "\n",
      "Epoch  210\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9491796718687475, 0.865979381443299]\n",
      "Validation -  [0.5, 0.48157051282051283, 0.43181818181818177]\n",
      "Test -  [0.42, 0.3794070512820513, 0.3829787234042554]\n",
      "\n",
      "Epoch  211\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.78, 0.9371748699479792, 0.7659574468085107]\n",
      "Validation -  [0.53, 0.5248397435897436, 0.4597701149425287]\n",
      "Test -  [0.42, 0.45713141025641024, 0.3829787234042554]\n",
      "\n",
      "Epoch  212\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9375750300120047, 0.8125]\n",
      "Validation -  [0.57, 0.5140224358974359, 0.4941176470588235]\n",
      "Test -  [0.51, 0.45232371794871795, 0.4948453608247423]\n",
      "\n",
      "Epoch  213\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9303721488595438, 0.7912087912087913]\n",
      "Validation -  [0.46, 0.515625, 0.38636363636363635]\n",
      "Test -  [0.44, 0.42908653846153855, 0.3913043478260869]\n",
      "\n",
      "Epoch  214\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9359743897559024, 0.8367346938775511]\n",
      "Validation -  [0.53, 0.5236378205128205, 0.44705882352941173]\n",
      "Test -  [0.43, 0.3790064102564103, 0.3448275862068966]\n",
      "\n",
      "Epoch  215\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9191676670668267, 0.7741935483870968]\n",
      "Validation -  [0.54, 0.5564903846153846, 0.46511627906976744]\n",
      "Test -  [0.43, 0.39342948717948717, 0.37362637362637363]\n",
      "\n",
      "Epoch  216\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9367747098839536, 0.8421052631578948]\n",
      "Validation -  [0.46, 0.4358974358974359, 0.372093023255814]\n",
      "Test -  [0.49, 0.4411057692307692, 0.41379310344827586]\n",
      "\n",
      "Epoch  217\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9315726290516206, 0.8125]\n",
      "Validation -  [0.55, 0.516826923076923, 0.4578313253012048]\n",
      "Test -  [0.52, 0.48517628205128205, 0.45454545454545453]\n",
      "\n",
      "Epoch  218\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9367747098839535, 0.86]\n",
      "Validation -  [0.49, 0.5048076923076923, 0.4000000000000001]\n",
      "Test -  [0.53, 0.46474358974358976, 0.47191011235955055]\n",
      "\n",
      "Epoch  219\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9315726290516206, 0.7872340425531916]\n",
      "Validation -  [0.53, 0.5092147435897436, 0.43373493975903615]\n",
      "Test -  [0.48, 0.4791666666666667, 0.4222222222222222]\n",
      "\n",
      "Epoch  220\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9243697478991596, 0.8085106382978724]\n",
      "Validation -  [0.52, 0.48317307692307687, 0.4418604651162791]\n",
      "Test -  [0.4, 0.3577724358974359, 0.3617021276595745]\n",
      "\n",
      "Epoch  221\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9443777511004401, 0.845360824742268]\n",
      "Validation -  [0.52, 0.4767628205128205, 0.4418604651162791]\n",
      "Test -  [0.47, 0.4411057692307693, 0.4175824175824176]\n",
      "\n",
      "Epoch  222\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9355742296918766, 0.8172043010752689]\n",
      "Validation -  [0.54, 0.547676282051282, 0.425]\n",
      "Test -  [0.44, 0.4042467948717949, 0.3913043478260869]\n",
      "\n",
      "Epoch  223\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9611844737895159, 0.8421052631578948]\n",
      "Validation -  [0.51, 0.5248397435897435, 0.4731182795698925]\n",
      "Test -  [0.45, 0.4326923076923077, 0.3956043956043956]\n",
      "\n",
      "Epoch  224\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9455782312925171, 0.8041237113402062]\n",
      "Validation -  [0.46, 0.46474358974358976, 0.35714285714285715]\n",
      "Test -  [0.46, 0.42107371794871795, 0.39999999999999997]\n",
      "\n",
      "Epoch  225\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9359743897559023, 0.8043478260869564]\n",
      "Validation -  [0.55, 0.5048076923076923, 0.4827586206896552]\n",
      "Test -  [0.44, 0.45392628205128205, 0.4285714285714286]\n",
      "\n",
      "Epoch  226\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9271708683473389, 0.8163265306122448]\n",
      "Validation -  [0.54, 0.563301282051282, 0.4772727272727273]\n",
      "Test -  [0.42, 0.43028846153846156, 0.3829787234042554]\n",
      "\n",
      "Epoch  227\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9483793517406962, 0.8541666666666666]\n",
      "Validation -  [0.51, 0.4947916666666667, 0.43678160919540227]\n",
      "Test -  [0.5, 0.4759615384615385, 0.45652173913043476]\n",
      "\n",
      "Epoch  228\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9395758303321329, 0.8125]\n",
      "Validation -  [0.46, 0.468349358974359, 0.35714285714285715]\n",
      "Test -  [0.47, 0.38701923076923067, 0.40449438202247195]\n",
      "\n",
      "Epoch  229\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9359743897559023, 0.8387096774193549]\n",
      "Validation -  [0.57, 0.547676282051282, 0.5057471264367815]\n",
      "Test -  [0.43, 0.41546474358974356, 0.4123711340206186]\n",
      "\n",
      "Epoch  230\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9443777511004401, 0.8125]\n",
      "Validation -  [0.48, 0.48918269230769235, 0.3953488372093023]\n",
      "Test -  [0.45, 0.4635416666666667, 0.3956043956043956]\n",
      "\n",
      "Epoch  231\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9247699079631853, 0.8421052631578948]\n",
      "Validation -  [0.48, 0.43028846153846156, 0.3658536585365854]\n",
      "Test -  [0.48, 0.45552884615384615, 0.4583333333333333]\n",
      "\n",
      "Epoch  232\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9403761504601841, 0.8297872340425532]\n",
      "Validation -  [0.61, 0.5641025641025641, 0.5517241379310345]\n",
      "Test -  [0.46, 0.4306891025641026, 0.38636363636363635]\n",
      "\n",
      "Epoch  233\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9339735894357744, 0.7956989247311828]\n",
      "Validation -  [0.52, 0.5332532051282051, 0.4666666666666667]\n",
      "Test -  [0.45, 0.4246794871794872, 0.3956043956043956]\n",
      "\n",
      "Epoch  234\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9451780712284914, 0.8247422680412372]\n",
      "Validation -  [0.45, 0.46434294871794873, 0.36781609195402293]\n",
      "Test -  [0.47, 0.45032051282051283, 0.3908045977011494]\n",
      "\n",
      "Epoch  235\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9343737494997999, 0.8571428571428571]\n",
      "Validation -  [0.48, 0.4443108974358974, 0.4090909090909091]\n",
      "Test -  [0.42, 0.42908653846153844, 0.3409090909090909]\n",
      "\n",
      "Epoch  236\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9311724689875951, 0.8333333333333334]\n",
      "Validation -  [0.55, 0.5348557692307692, 0.5161290322580646]\n",
      "Test -  [0.42, 0.4383012820512821, 0.3695652173913044]\n",
      "\n",
      "Epoch  237\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9207683073229291, 0.8163265306122448]\n",
      "Validation -  [0.52, 0.5244391025641026, 0.45454545454545453]\n",
      "Test -  [0.46, 0.40184294871794873, 0.41304347826086957]\n",
      "\n",
      "Epoch  238\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.938375350140056, 0.8247422680412372]\n",
      "Validation -  [0.45, 0.4815705128205128, 0.3529411764705882]\n",
      "Test -  [0.41, 0.4034455128205128, 0.37894736842105264]\n",
      "\n",
      "Epoch  239\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9399759903961585, 0.8163265306122448]\n",
      "Validation -  [0.55, 0.547676282051282, 0.4444444444444444]\n",
      "Test -  [0.44, 0.4391025641025641, 0.3913043478260869]\n",
      "\n",
      "Epoch  240\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9479791916766707, 0.8333333333333334]\n",
      "Validation -  [0.51, 0.49278846153846156, 0.3636363636363637]\n",
      "Test -  [0.44, 0.4515224358974359, 0.3488372093023256]\n",
      "\n",
      "Epoch  241\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9471788715486193, 0.8172043010752689]\n",
      "Validation -  [0.57, 0.6033653846153847, 0.5168539325842697]\n",
      "Test -  [0.45, 0.4258814102564103, 0.3956043956043956]\n",
      "\n",
      "Epoch  242\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9403761504601842, 0.8247422680412372]\n",
      "Validation -  [0.51, 0.5344551282051282, 0.44943820224719094]\n",
      "Test -  [0.47, 0.436698717948718, 0.4175824175824176]\n",
      "\n",
      "Epoch  243\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9335734293717487, 0.8172043010752689]\n",
      "Validation -  [0.5, 0.48036858974358976, 0.4047619047619048]\n",
      "Test -  [0.46, 0.4354967948717949, 0.4489795918367347]\n",
      "\n",
      "Epoch  244\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9299719887955181, 0.8484848484848485]\n",
      "Validation -  [0.56, 0.5332532051282052, 0.4761904761904762]\n",
      "Test -  [0.43, 0.44270833333333337, 0.42424242424242425]\n",
      "\n",
      "Epoch  245\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9335734293717486, 0.8210526315789474]\n",
      "Validation -  [0.49, 0.516426282051282, 0.41379310344827586]\n",
      "Test -  [0.42, 0.3577724358974359, 0.3958333333333333]\n",
      "\n",
      "Epoch  246\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9615846338535413, 0.8387096774193549]\n",
      "Validation -  [0.45, 0.48878205128205127, 0.38202247191011235]\n",
      "Test -  [0.49, 0.46314102564102566, 0.43956043956043955]\n",
      "\n",
      "Epoch  247\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.89, 0.9523809523809523, 0.8842105263157896]\n",
      "Validation -  [0.52, 0.5236378205128205, 0.42857142857142855]\n",
      "Test -  [0.34, 0.38621794871794873, 0.3125]\n",
      "\n",
      "Epoch  248\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9487795118047218, 0.8387096774193549]\n",
      "Validation -  [0.49, 0.4823717948717949, 0.42696629213483145]\n",
      "Test -  [0.45, 0.41907051282051283, 0.40860215053763443]\n",
      "\n",
      "Epoch  249\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9279711884753902, 0.8247422680412372]\n",
      "Validation -  [0.55, 0.5436698717948718, 0.4578313253012048]\n",
      "Test -  [0.37, 0.36498397435897434, 0.3225806451612903]\n",
      "\n",
      "Epoch  250\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9359743897559024, 0.8]\n",
      "Validation -  [0.51, 0.4987980769230769, 0.4615384615384615]\n",
      "Test -  [0.44, 0.4230769230769231, 0.4166666666666667]\n",
      "\n",
      "Epoch  251\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9223689475790317, 0.8247422680412372]\n",
      "Validation -  [0.45, 0.42107371794871795, 0.36781609195402293]\n",
      "Test -  [0.5, 0.43750000000000006, 0.4444444444444445]\n",
      "\n",
      "Epoch  252\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9283713485394158, 0.8571428571428571]\n",
      "Validation -  [0.49, 0.500801282051282, 0.41379310344827586]\n",
      "Test -  [0.46, 0.4290865384615385, 0.425531914893617]\n",
      "\n",
      "Epoch  253\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9359743897559023, 0.8367346938775511]\n",
      "Validation -  [0.48, 0.44591346153846156, 0.4090909090909091]\n",
      "Test -  [0.41, 0.33613782051282054, 0.3655913978494624]\n",
      "\n",
      "Epoch  254\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9411764705882353, 0.84]\n",
      "Validation -  [0.52, 0.5200320512820513, 0.4418604651162791]\n",
      "Test -  [0.42, 0.4086538461538462, 0.3829787234042554]\n",
      "\n",
      "Epoch  255\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9315726290516206, 0.8210526315789474]\n",
      "Validation -  [0.55, 0.5649038461538461, 0.49438202247191015]\n",
      "Test -  [0.44, 0.39342948717948717, 0.4166666666666667]\n",
      "\n",
      "Epoch  256\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9211684673869547, 0.8118811881188118]\n",
      "Validation -  [0.48, 0.4379006410256411, 0.43478260869565216]\n",
      "Test -  [0.42, 0.39943910256410253, 0.35555555555555557]\n",
      "\n",
      "Epoch  257\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9359743897559025, 0.7916666666666666]\n",
      "Validation -  [0.55, 0.4899839743589744, 0.47058823529411764]\n",
      "Test -  [0.37, 0.3838141025641026, 0.3505154639175258]\n",
      "\n",
      "Epoch  258\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9131652661064426, 0.7872340425531916]\n",
      "Validation -  [0.5, 0.48317307692307687, 0.4047619047619048]\n",
      "Test -  [0.48, 0.4274839743589744, 0.44680851063829785]\n",
      "\n",
      "Epoch  259\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9363745498199278, 0.787878787878788]\n",
      "Validation -  [0.52, 0.5136217948717948, 0.42857142857142855]\n",
      "Test -  [0.45, 0.4763621794871795, 0.46601941747572817]\n",
      "\n",
      "Epoch  260\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9303721488595438, 0.8172043010752689]\n",
      "Validation -  [0.54, 0.4947916666666667, 0.4390243902439025]\n",
      "Test -  [0.47, 0.45192307692307687, 0.45360824742268036]\n",
      "\n",
      "Epoch  261\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9471788715486195, 0.8431372549019607]\n",
      "Validation -  [0.52, 0.531650641025641, 0.4666666666666667]\n",
      "Test -  [0.41, 0.38782051282051283, 0.33707865168539325]\n",
      "\n",
      "Epoch  262\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9371748699479792, 0.8297872340425532]\n",
      "Validation -  [0.52, 0.4979967948717949, 0.4666666666666667]\n",
      "Test -  [0.38, 0.3786057692307692, 0.32608695652173914]\n",
      "\n",
      "Epoch  263\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9275710284113646, 0.8514851485148515]\n",
      "Validation -  [0.5, 0.5296474358974359, 0.4444444444444445]\n",
      "Test -  [0.44, 0.4511217948717949, 0.4166666666666667]\n",
      "\n",
      "Epoch  264\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9407763105242097, 0.84]\n",
      "Validation -  [0.49, 0.53125, 0.45161290322580644]\n",
      "Test -  [0.4, 0.39342948717948717, 0.34782608695652173]\n",
      "\n",
      "Epoch  265\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9499799919967986, 0.8125]\n",
      "Validation -  [0.6, 0.5412660256410257, 0.5555555555555556]\n",
      "Test -  [0.36, 0.391025641025641, 0.3725490196078432]\n",
      "\n",
      "Epoch  266\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9267707082833134, 0.7916666666666666]\n",
      "Validation -  [0.53, 0.5152243589743589, 0.4835164835164835]\n",
      "Test -  [0.44, 0.4042467948717949, 0.3777777777777778]\n",
      "\n",
      "Epoch  267\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.88, 0.9475790316126451, 0.8749999999999999]\n",
      "Validation -  [0.44, 0.5, 0.4042553191489362]\n",
      "Test -  [0.45, 0.4254807692307692, 0.40860215053763443]\n",
      "\n",
      "Epoch  268\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9451780712284914, 0.851063829787234]\n",
      "Validation -  [0.51, 0.5, 0.44943820224719094]\n",
      "Test -  [0.49, 0.4246794871794872, 0.48484848484848486]\n",
      "\n",
      "Epoch  269\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9243697478991597, 0.8200000000000001]\n",
      "Validation -  [0.51, 0.516426282051282, 0.43678160919540227]\n",
      "Test -  [0.43, 0.42868589743589747, 0.38709677419354843]\n",
      "\n",
      "Epoch  270\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9375750300120048, 0.86]\n",
      "Validation -  [0.53, 0.49479166666666663, 0.4597701149425287]\n",
      "Test -  [0.45, 0.4182692307692308, 0.42105263157894735]\n",
      "\n",
      "Epoch  271\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9339735894357744, 0.8085106382978724]\n",
      "Validation -  [0.57, 0.5120192307692307, 0.5376344086021506]\n",
      "Test -  [0.44, 0.41546474358974356, 0.3636363636363636]\n",
      "\n",
      "Epoch  272\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9363745498199278, 0.8333333333333334]\n",
      "Validation -  [0.56, 0.4935897435897436, 0.5111111111111111]\n",
      "Test -  [0.43, 0.4126602564102564, 0.38709677419354843]\n",
      "\n",
      "Epoch  273\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9371748699479792, 0.8125]\n",
      "Validation -  [0.5, 0.44551282051282054, 0.45652173913043476]\n",
      "Test -  [0.38, 0.3774038461538461, 0.3673469387755102]\n",
      "\n",
      "Epoch  274\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9255702280912366, 0.7956989247311828]\n",
      "Validation -  [0.56, 0.5548878205128205, 0.5]\n",
      "Test -  [0.43, 0.4318910256410257, 0.37362637362637363]\n",
      "\n",
      "Epoch  275\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.88, 0.9491796718687475, 0.8775510204081632]\n",
      "Validation -  [0.56, 0.5388621794871795, 0.45]\n",
      "Test -  [0.47, 0.48157051282051283, 0.4301075268817204]\n",
      "\n",
      "Epoch  276\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9451780712284914, 0.8247422680412372]\n",
      "Validation -  [0.46, 0.43469551282051283, 0.39999999999999997]\n",
      "Test -  [0.41, 0.3894230769230769, 0.3655913978494624]\n",
      "\n",
      "Epoch  277\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9375750300120047, 0.865979381443299]\n",
      "Validation -  [0.55, 0.546073717948718, 0.47058823529411764]\n",
      "Test -  [0.49, 0.47035256410256415, 0.45161290322580644]\n",
      "\n",
      "Epoch  278\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9451780712284914, 0.8210526315789474]\n",
      "Validation -  [0.52, 0.4483173076923077, 0.4666666666666667]\n",
      "Test -  [0.46, 0.4487179487179487, 0.39999999999999997]\n",
      "\n",
      "Epoch  279\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9371748699479793, 0.8247422680412372]\n",
      "Validation -  [0.52, 0.5088141025641025, 0.4418604651162791]\n",
      "Test -  [0.48, 0.4619391025641026, 0.44680851063829785]\n",
      "\n",
      "Epoch  280\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9387755102040816, 0.8125]\n",
      "Validation -  [0.57, 0.5765224358974359, 0.5168539325842697]\n",
      "Test -  [0.48, 0.4499198717948718, 0.43478260869565216]\n",
      "\n",
      "Epoch  281\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.938375350140056, 0.8484848484848485]\n",
      "Validation -  [0.49, 0.4939903846153847, 0.3703703703703703]\n",
      "Test -  [0.45, 0.4567307692307693, 0.42105263157894735]\n",
      "\n",
      "Epoch  282\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9487795118047218, 0.845360824742268]\n",
      "Validation -  [0.45, 0.4939903846153846, 0.3529411764705882]\n",
      "Test -  [0.49, 0.4527243589743589, 0.42696629213483145]\n",
      "\n",
      "Epoch  283\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.948779511804722, 0.8297872340425532]\n",
      "Validation -  [0.59, 0.5340544871794872, 0.4938271604938272]\n",
      "Test -  [0.47, 0.40424679487179493, 0.40449438202247195]\n",
      "\n",
      "Epoch  284\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.76, 0.9115646258503401, 0.7446808510638299]\n",
      "Validation -  [0.52, 0.49559294871794873, 0.4666666666666667]\n",
      "Test -  [0.49, 0.452724358974359, 0.43956043956043955]\n",
      "\n",
      "Epoch  285\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.938375350140056, 0.8043478260869564]\n",
      "Validation -  [0.51, 0.5176282051282051, 0.3950617283950617]\n",
      "Test -  [0.48, 0.453125, 0.3953488372093023]\n",
      "\n",
      "Epoch  286\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9527811124449781, 0.851063829787234]\n",
      "Validation -  [0.52, 0.5372596153846154, 0.42857142857142855]\n",
      "Test -  [0.49, 0.4198717948717949, 0.45161290322580644]\n",
      "\n",
      "Epoch  287\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9255702280912366, 0.8367346938775511]\n",
      "Validation -  [0.5, 0.5112179487179487, 0.39024390243902435]\n",
      "Test -  [0.46, 0.43509615384615385, 0.39999999999999997]\n",
      "\n",
      "Epoch  288\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.938375350140056, 0.8712871287128714]\n",
      "Validation -  [0.47, 0.4747596153846154, 0.40449438202247195]\n",
      "Test -  [0.5, 0.47115384615384615, 0.4444444444444445]\n",
      "\n",
      "Epoch  289\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9339735894357744, 0.8085106382978724]\n",
      "Validation -  [0.52, 0.5028044871794872, 0.4146341463414634]\n",
      "Test -  [0.48, 0.44471153846153844, 0.44680851063829785]\n",
      "\n",
      "Epoch  290\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9367747098839536, 0.8421052631578948]\n",
      "Validation -  [0.51, 0.4651442307692308, 0.42352941176470593]\n",
      "Test -  [0.45, 0.40905448717948717, 0.3956043956043956]\n",
      "\n",
      "Epoch  291\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9447779111644659, 0.8333333333333334]\n",
      "Validation -  [0.49, 0.5204326923076923, 0.41379310344827586]\n",
      "Test -  [0.44, 0.4126602564102564, 0.3777777777777778]\n",
      "\n",
      "Epoch  292\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9359743897559025, 0.845360824742268]\n",
      "Validation -  [0.52, 0.5068108974358975, 0.4418604651162791]\n",
      "Test -  [0.49, 0.47235576923076916, 0.45161290322580644]\n",
      "\n",
      "Epoch  293\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9319727891156462, 0.8571428571428571]\n",
      "Validation -  [0.54, 0.5200320512820512, 0.45238095238095233]\n",
      "Test -  [0.46, 0.43309294871794873, 0.39999999999999997]\n",
      "\n",
      "Epoch  294\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9319727891156463, 0.8367346938775511]\n",
      "Validation -  [0.52, 0.5, 0.4418604651162791]\n",
      "Test -  [0.41, 0.39182692307692313, 0.3655913978494624]\n",
      "\n",
      "Epoch  295\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9427771108443377, 0.845360824742268]\n",
      "Validation -  [0.52, 0.500400641025641, 0.4666666666666667]\n",
      "Test -  [0.41, 0.3970352564102564, 0.40404040404040403]\n",
      "\n",
      "Epoch  296\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9423769507803121, 0.7872340425531916]\n",
      "Validation -  [0.51, 0.47916666666666663, 0.4731182795698925]\n",
      "Test -  [0.54, 0.4827724358974359, 0.5208333333333334]\n",
      "\n",
      "Epoch  297\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9415766306522609, 0.8210526315789474]\n",
      "Validation -  [0.53, 0.5124198717948718, 0.47191011235955055]\n",
      "Test -  [0.45, 0.4042467948717949, 0.36781609195402293]\n",
      "\n",
      "Epoch  298\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9311724689875951, 0.8367346938775511]\n",
      "Validation -  [0.53, 0.5376602564102564, 0.5052631578947369]\n",
      "Test -  [0.45, 0.4134615384615385, 0.43298969072164945]\n",
      "\n",
      "Epoch  299\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9327731092436975, 0.8085106382978724]\n",
      "Validation -  [0.54, 0.48918269230769235, 0.4772727272727273]\n",
      "Test -  [0.43, 0.41105769230769235, 0.38709677419354843]\n",
      "\n",
      "Epoch  300\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.929171668667467, 0.8235294117647058]\n",
      "Validation -  [0.57, 0.5192307692307693, 0.5057471264367815]\n",
      "Test -  [0.41, 0.4310897435897436, 0.3917525773195876]\n",
      "\n",
      "Epoch  301\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9123649459783914, 0.8172043010752689]\n",
      "Validation -  [0.56, 0.5436698717948718, 0.5]\n",
      "Test -  [0.5, 0.4759615384615385, 0.4680851063829787]\n",
      "\n",
      "Epoch  302\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9447779111644659, 0.8541666666666666]\n",
      "Validation -  [0.44, 0.42708333333333337, 0.3636363636363636]\n",
      "Test -  [0.47, 0.4767628205128205, 0.4175824175824176]\n",
      "\n",
      "Epoch  303\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9167667066826731, 0.8210526315789474]\n",
      "Validation -  [0.51, 0.5140224358974359, 0.43678160919540227]\n",
      "Test -  [0.46, 0.4278846153846154, 0.45999999999999996]\n",
      "\n",
      "Epoch  304\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9503801520608243, 0.8541666666666666]\n",
      "Validation -  [0.56, 0.5556891025641025, 0.5111111111111111]\n",
      "Test -  [0.46, 0.4723557692307692, 0.41304347826086957]\n",
      "\n",
      "Epoch  305\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9327731092436975, 0.8125]\n",
      "Validation -  [0.55, 0.516025641025641, 0.5054945054945056]\n",
      "Test -  [0.47, 0.4114583333333333, 0.40449438202247195]\n",
      "\n",
      "Epoch  306\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9503801520608244, 0.8297872340425532]\n",
      "Validation -  [0.53, 0.4767628205128206, 0.4597701149425287]\n",
      "Test -  [0.44, 0.4086538461538462, 0.3488372093023256]\n",
      "\n",
      "Epoch  307\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9343737494997999, 0.7956989247311828]\n",
      "Validation -  [0.55, 0.5112179487179487, 0.4578313253012048]\n",
      "Test -  [0.51, 0.4631410256410257, 0.4731182795698925]\n",
      "\n",
      "Epoch  308\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9419767907162865, 0.8043478260869564]\n",
      "Validation -  [0.48, 0.46634615384615385, 0.3953488372093023]\n",
      "Test -  [0.5, 0.44911858974358976, 0.43181818181818177]\n",
      "\n",
      "Epoch  309\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9483793517406962, 0.8172043010752689]\n",
      "Validation -  [0.56, 0.5116185897435898, 0.5]\n",
      "Test -  [0.5, 0.4246794871794872, 0.4186046511627907]\n",
      "\n",
      "Epoch  310\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9471788715486195, 0.8514851485148515]\n",
      "Validation -  [0.43, 0.43349358974358976, 0.37362637362637363]\n",
      "Test -  [0.46, 0.4707532051282052, 0.41304347826086957]\n",
      "\n",
      "Epoch  311\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9295718287314926, 0.845360824742268]\n",
      "Validation -  [0.5, 0.49519230769230765, 0.39024390243902435]\n",
      "Test -  [0.44, 0.436698717948718, 0.3777777777777778]\n",
      "\n",
      "Epoch  312\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9391756702681072, 0.8163265306122448]\n",
      "Validation -  [0.5, 0.5276442307692307, 0.4047619047619048]\n",
      "Test -  [0.41, 0.390625, 0.3917525773195876]\n",
      "\n",
      "Epoch  313\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9499799919967986, 0.845360824742268]\n",
      "Validation -  [0.5, 0.5048076923076923, 0.4680851063829787]\n",
      "Test -  [0.46, 0.42427884615384615, 0.4375]\n",
      "\n",
      "Epoch  314\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9431772709083633, 0.845360824742268]\n",
      "Validation -  [0.52, 0.4743589743589744, 0.4666666666666667]\n",
      "Test -  [0.46, 0.48036858974358976, 0.4489795918367347]\n",
      "\n",
      "Epoch  315\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.927170868347339, 0.8125]\n",
      "Validation -  [0.48, 0.4907852564102564, 0.4583333333333333]\n",
      "Test -  [0.5, 0.46153846153846156, 0.4680851063829787]\n",
      "\n",
      "Epoch  316\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9243697478991596, 0.8282828282828283]\n",
      "Validation -  [0.51, 0.5380608974358975, 0.44943820224719094]\n",
      "Test -  [0.48, 0.4415064102564103, 0.43478260869565216]\n",
      "\n",
      "Epoch  317\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9315726290516206, 0.8297872340425532]\n",
      "Validation -  [0.54, 0.5104166666666666, 0.46511627906976744]\n",
      "Test -  [0.46, 0.44350961538461536, 0.45999999999999996]\n",
      "\n",
      "Epoch  318\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.956782713085234, 0.8484848484848485]\n",
      "Validation -  [0.48, 0.46394230769230776, 0.4222222222222222]\n",
      "Test -  [0.4, 0.3581730769230769, 0.3333333333333333]\n",
      "\n",
      "Epoch  319\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9651860744297719, 0.86]\n",
      "Validation -  [0.54, 0.48717948717948717, 0.5]\n",
      "Test -  [0.5, 0.4495192307692308, 0.4897959183673469]\n",
      "\n",
      "Epoch  320\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9419767907162866, 0.86]\n",
      "Validation -  [0.5, 0.5024038461538461, 0.4186046511627907]\n",
      "Test -  [0.45, 0.41306089743589747, 0.4444444444444445]\n",
      "\n",
      "Epoch  321\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9359743897559024, 0.8297872340425532]\n",
      "Validation -  [0.54, 0.5288461538461539, 0.4772727272727273]\n",
      "Test -  [0.42, 0.4050480769230769, 0.4081632653061225]\n",
      "\n",
      "Epoch  322\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9395758303321329, 0.8367346938775511]\n",
      "Validation -  [0.53, 0.5200320512820513, 0.47191011235955055]\n",
      "Test -  [0.41, 0.39503205128205127, 0.37894736842105264]\n",
      "\n",
      "Epoch  323\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9299719887955182, 0.7741935483870968]\n",
      "Validation -  [0.5, 0.4807692307692308, 0.4444444444444445]\n",
      "Test -  [0.42, 0.4595352564102564, 0.42000000000000004]\n",
      "\n",
      "Epoch  324\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9351740696278511, 0.8333333333333334]\n",
      "Validation -  [0.43, 0.43749999999999994, 0.38709677419354843]\n",
      "Test -  [0.43, 0.3858173076923077, 0.39999999999999997]\n",
      "\n",
      "Epoch  325\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9479791916766707, 0.8571428571428571]\n",
      "Validation -  [0.47, 0.46033653846153844, 0.3908045977011494]\n",
      "Test -  [0.43, 0.4130608974358974, 0.38709677419354843]\n",
      "\n",
      "Epoch  326\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9231692677070827, 0.845360824742268]\n",
      "Validation -  [0.5, 0.4875801282051282, 0.43181818181818177]\n",
      "Test -  [0.48, 0.44270833333333337, 0.46938775510204084]\n",
      "\n",
      "Epoch  327\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.936374549819928, 0.8737864077669903]\n",
      "Validation -  [0.52, 0.5320512820512822, 0.4782608695652174]\n",
      "Test -  [0.42, 0.4094551282051282, 0.3409090909090909]\n",
      "\n",
      "Epoch  328\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9175670268107242, 0.7789473684210527]\n",
      "Validation -  [0.42, 0.44150641025641024, 0.35555555555555557]\n",
      "Test -  [0.43, 0.40224358974358976, 0.37362637362637363]\n",
      "\n",
      "Epoch  329\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9419767907162865, 0.8247422680412372]\n",
      "Validation -  [0.59, 0.547676282051282, 0.5393258426966292]\n",
      "Test -  [0.54, 0.46955128205128205, 0.5]\n",
      "\n",
      "Epoch  330\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.89, 0.9543817527010805, 0.8817204301075269]\n",
      "Validation -  [0.51, 0.5060096153846154, 0.40963855421686746]\n",
      "Test -  [0.48, 0.44551282051282054, 0.43478260869565216]\n",
      "\n",
      "Epoch  331\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9515806322529012, 0.8297872340425532]\n",
      "Validation -  [0.49, 0.48677884615384615, 0.42696629213483145]\n",
      "Test -  [0.39, 0.4074519230769231, 0.3960396039603961]\n",
      "\n",
      "Epoch  332\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9491796718687475, 0.8541666666666666]\n",
      "Validation -  [0.55, 0.5052083333333333, 0.49438202247191015]\n",
      "Test -  [0.46, 0.4379006410256411, 0.41304347826086957]\n",
      "\n",
      "Epoch  333\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9443777511004401, 0.8387096774193549]\n",
      "Validation -  [0.57, 0.5180288461538461, 0.5274725274725274]\n",
      "Test -  [0.43, 0.3830128205128205, 0.37362637362637363]\n",
      "\n",
      "Epoch  334\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9283713485394158, 0.7872340425531916]\n",
      "Validation -  [0.52, 0.530448717948718, 0.42857142857142855]\n",
      "Test -  [0.4, 0.3866185897435897, 0.3333333333333333]\n",
      "\n",
      "Epoch  335\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9387755102040816, 0.7789473684210527]\n",
      "Validation -  [0.47, 0.46995192307692313, 0.3764705882352941]\n",
      "Test -  [0.51, 0.48477564102564097, 0.44943820224719094]\n",
      "\n",
      "Epoch  336\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9535814325730292, 0.865979381443299]\n",
      "Validation -  [0.53, 0.4907852564102564, 0.4597701149425287]\n",
      "Test -  [0.41, 0.43149038461538464, 0.3655913978494624]\n",
      "\n",
      "Epoch  337\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.88, 0.9463785514205683, 0.8799999999999999]\n",
      "Validation -  [0.49, 0.4615384615384615, 0.4000000000000001]\n",
      "Test -  [0.38, 0.39663461538461536, 0.3541666666666667]\n",
      "\n",
      "Epoch  338\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9363745498199281, 0.8333333333333334]\n",
      "Validation -  [0.52, 0.500400641025641, 0.45454545454545453]\n",
      "Test -  [0.47, 0.44471153846153844, 0.4175824175824176]\n",
      "\n",
      "Epoch  339\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9343737494997999, 0.8247422680412372]\n",
      "Validation -  [0.54, 0.5436698717948718, 0.4888888888888889]\n",
      "Test -  [0.45, 0.45592948717948717, 0.40860215053763443]\n",
      "\n",
      "Epoch  340\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.88, 0.9499799919967987, 0.8799999999999999]\n",
      "Validation -  [0.51, 0.49158653846153844, 0.40963855421686746]\n",
      "Test -  [0.45, 0.4647435897435898, 0.3529411764705882]\n",
      "\n",
      "Epoch  341\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9471788715486193, 0.8200000000000001]\n",
      "Validation -  [0.5, 0.49439102564102566, 0.4444444444444445]\n",
      "Test -  [0.46, 0.4266826923076923, 0.41304347826086957]\n",
      "\n",
      "Epoch  342\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.943577430972389, 0.8247422680412372]\n",
      "Validation -  [0.56, 0.5620993589743589, 0.4761904761904762]\n",
      "Test -  [0.48, 0.4579326923076923, 0.43478260869565216]\n",
      "\n",
      "Epoch  343\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9315726290516206, 0.782608695652174]\n",
      "Validation -  [0.55, 0.5400641025641025, 0.49438202247191015]\n",
      "Test -  [0.44, 0.406650641025641, 0.4042553191489362]\n",
      "\n",
      "Epoch  344\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9399759903961584, 0.8125]\n",
      "Validation -  [0.5, 0.48397435897435903, 0.375]\n",
      "Test -  [0.44, 0.39903846153846156, 0.4042553191489362]\n",
      "\n",
      "Epoch  345\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9223689475790317, 0.8125]\n",
      "Validation -  [0.54, 0.5048076923076923, 0.425]\n",
      "Test -  [0.46, 0.44831730769230765, 0.39999999999999997]\n",
      "\n",
      "Epoch  346\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9335734293717487, 0.8571428571428571]\n",
      "Validation -  [0.47, 0.5252403846153846, 0.3908045977011494]\n",
      "Test -  [0.39, 0.3737980769230769, 0.34408602150537637]\n",
      "\n",
      "Epoch  347\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9511804721888755, 0.8333333333333334]\n",
      "Validation -  [0.5, 0.5264423076923076, 0.4791666666666667]\n",
      "Test -  [0.47, 0.46875000000000006, 0.4421052631578947]\n",
      "\n",
      "Epoch  348\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9467787114845938, 0.8041237113402062]\n",
      "Validation -  [0.46, 0.46033653846153844, 0.39999999999999997]\n",
      "Test -  [0.42, 0.3934294871794872, 0.4081632653061225]\n",
      "\n",
      "Epoch  349\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9051620648259303, 0.8]\n",
      "Validation -  [0.51, 0.5532852564102564, 0.4842105263157895]\n",
      "Test -  [0.38, 0.39783653846153844, 0.3404255319148936]\n",
      "\n",
      "Epoch  350\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9427771108443378, 0.7789473684210527]\n",
      "Validation -  [0.49, 0.4699519230769231, 0.43956043956043955]\n",
      "Test -  [0.48, 0.43108974358974367, 0.48000000000000004]\n",
      "\n",
      "Epoch  351\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9355742296918766, 0.8247422680412372]\n",
      "Validation -  [0.51, 0.5100160256410257, 0.4731182795698925]\n",
      "Test -  [0.48, 0.4675480769230769, 0.43478260869565216]\n",
      "\n",
      "Epoch  352\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9487795118047219, 0.8367346938775511]\n",
      "Validation -  [0.56, 0.5132211538461539, 0.5111111111111111]\n",
      "Test -  [0.44, 0.437099358974359, 0.4042553191489362]\n",
      "\n",
      "Epoch  353\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9199679871948779, 0.7959183673469387]\n",
      "Validation -  [0.48, 0.5028044871794872, 0.4222222222222222]\n",
      "Test -  [0.45, 0.46354166666666663, 0.46601941747572817]\n",
      "\n",
      "Epoch  354\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9619847939175671, 0.8421052631578948]\n",
      "Validation -  [0.49, 0.4947916666666667, 0.42696629213483145]\n",
      "Test -  [0.5, 0.46995192307692313, 0.4791666666666667]\n",
      "\n",
      "Epoch  355\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9507803121248499, 0.865979381443299]\n",
      "Validation -  [0.51, 0.4679487179487179, 0.42352941176470593]\n",
      "Test -  [0.44, 0.3766025641025641, 0.4042553191489362]\n",
      "\n",
      "Epoch  356\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9487795118047219, 0.8367346938775511]\n",
      "Validation -  [0.48, 0.5168269230769231, 0.3953488372093023]\n",
      "Test -  [0.49, 0.484375, 0.4742268041237114]\n",
      "\n",
      "Epoch  357\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9191676670668267, 0.8118811881188118]\n",
      "Validation -  [0.55, 0.546073717948718, 0.49438202247191015]\n",
      "Test -  [0.39, 0.4082532051282051, 0.37113402061855677]\n",
      "\n",
      "Epoch  358\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9307723089235694, 0.8200000000000001]\n",
      "Validation -  [0.54, 0.5292467948717948, 0.4888888888888889]\n",
      "Test -  [0.45, 0.4134615384615385, 0.43298969072164945]\n",
      "\n",
      "Epoch  359\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9343737494997999, 0.8247422680412372]\n",
      "Validation -  [0.54, 0.5188301282051282, 0.5208333333333334]\n",
      "Test -  [0.46, 0.44070512820512825, 0.45999999999999996]\n",
      "\n",
      "Epoch  360\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9415766306522609, 0.8514851485148515]\n",
      "Validation -  [0.53, 0.516426282051282, 0.5252525252525253]\n",
      "Test -  [0.38, 0.36578525641025644, 0.3541666666666667]\n",
      "\n",
      "Epoch  361\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9439775910364145, 0.84]\n",
      "Validation -  [0.47, 0.5084134615384616, 0.48543689320388356]\n",
      "Test -  [0.52, 0.5040064102564102, 0.5471698113207547]\n",
      "\n",
      "Epoch  362\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.945578231292517, 0.8571428571428571]\n",
      "Validation -  [0.51, 0.501602564102564, 0.4842105263157895]\n",
      "Test -  [0.5, 0.44631410256410253, 0.4791666666666667]\n",
      "\n",
      "Epoch  363\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9355742296918766, 0.86]\n",
      "Validation -  [0.46, 0.45432692307692313, 0.39999999999999997]\n",
      "Test -  [0.5, 0.5096153846153846, 0.5098039215686274]\n",
      "\n",
      "Epoch  364\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9387755102040816, 0.8333333333333334]\n",
      "Validation -  [0.48, 0.4819711538461539, 0.4583333333333333]\n",
      "Test -  [0.42, 0.41586538461538464, 0.3958333333333333]\n",
      "\n",
      "Epoch  365\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9395758303321329, 0.8235294117647058]\n",
      "Validation -  [0.53, 0.483573717948718, 0.4946236559139785]\n",
      "Test -  [0.41, 0.4118589743589744, 0.40404040404040403]\n",
      "\n",
      "Epoch  366\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.943577430972389, 0.8367346938775511]\n",
      "Validation -  [0.48, 0.48918269230769235, 0.46938775510204084]\n",
      "Test -  [0.42, 0.4146634615384616, 0.42000000000000004]\n",
      "\n",
      "Epoch  367\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9559823929571828, 0.8514851485148515]\n",
      "Validation -  [0.52, 0.5340544871794872, 0.4782608695652174]\n",
      "Test -  [0.47, 0.4643429487179488, 0.4752475247524752]\n",
      "\n",
      "Epoch  368\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9351740696278511, 0.8297872340425532]\n",
      "Validation -  [0.5, 0.530849358974359, 0.4680851063829787]\n",
      "Test -  [0.46, 0.44751602564102566, 0.4489795918367347]\n",
      "\n",
      "Epoch  369\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9379751900760305, 0.8484848484848485]\n",
      "Validation -  [0.48, 0.43669871794871795, 0.4222222222222222]\n",
      "Test -  [0.5, 0.4723557692307692, 0.4791666666666667]\n",
      "\n",
      "Epoch  370\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9511804721888757, 0.8333333333333334]\n",
      "Validation -  [0.55, 0.5288461538461539, 0.5054945054945056]\n",
      "Test -  [0.43, 0.45312500000000006, 0.42424242424242425]\n",
      "\n",
      "Epoch  371\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9403761504601841, 0.8163265306122448]\n",
      "Validation -  [0.49, 0.5060096153846154, 0.46315789473684216]\n",
      "Test -  [0.43, 0.4623397435897436, 0.4123711340206186]\n",
      "\n",
      "Epoch  372\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9343737494997999, 0.8247422680412372]\n",
      "Validation -  [0.52, 0.4867788461538462, 0.5]\n",
      "Test -  [0.42, 0.4362980769230769, 0.42000000000000004]\n",
      "\n",
      "Epoch  373\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9355742296918768, 0.8316831683168315]\n",
      "Validation -  [0.53, 0.5124198717948718, 0.47191011235955055]\n",
      "Test -  [0.47, 0.4238782051282052, 0.4301075268817204]\n",
      "\n",
      "Epoch  374\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9223689475790317, 0.7835051546391751]\n",
      "Validation -  [0.53, 0.5032051282051282, 0.47191011235955055]\n",
      "Test -  [0.39, 0.421875, 0.37113402061855677]\n",
      "\n",
      "Epoch  375\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9395758303321329, 0.8200000000000001]\n",
      "Validation -  [0.61, 0.5897435897435898, 0.5617977528089888]\n",
      "Test -  [0.42, 0.3926282051282051, 0.3829787234042554]\n",
      "\n",
      "Epoch  376\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9371748699479792, 0.8297872340425532]\n",
      "Validation -  [0.49, 0.5396634615384616, 0.45161290322580644]\n",
      "Test -  [0.44, 0.3942307692307692, 0.4166666666666667]\n",
      "\n",
      "Epoch  377\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9007603041216486, 0.8247422680412372]\n",
      "Validation -  [0.57, 0.5368589743589743, 0.5274725274725274]\n",
      "Test -  [0.44, 0.47676282051282054, 0.4166666666666667]\n",
      "\n",
      "Epoch  378\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9279711884753901, 0.8316831683168315]\n",
      "Validation -  [0.57, 0.5713141025641025, 0.5057471264367815]\n",
      "Test -  [0.53, 0.49399038461538464, 0.5154639175257733]\n",
      "\n",
      "Epoch  379\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9307723089235695, 0.7916666666666666]\n",
      "Validation -  [0.51, 0.5536858974358975, 0.40963855421686746]\n",
      "Test -  [0.39, 0.3629807692307692, 0.35789473684210527]\n",
      "\n",
      "Epoch  380\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.78, 0.9251700680272108, 0.7755102040816325]\n",
      "Validation -  [0.53, 0.5064102564102564, 0.44705882352941173]\n",
      "Test -  [0.45, 0.39503205128205127, 0.43298969072164945]\n",
      "\n",
      "Epoch  381\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9475790316126451, 0.8387096774193549]\n",
      "Validation -  [0.5, 0.46073717948717946, 0.43181818181818177]\n",
      "Test -  [0.47, 0.4475160256410257, 0.4175824175824176]\n",
      "\n",
      "Epoch  382\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9439775910364147, 0.8260869565217392]\n",
      "Validation -  [0.53, 0.5172275641025641, 0.47191011235955055]\n",
      "Test -  [0.5, 0.49078525641025644, 0.4680851063829787]\n",
      "\n",
      "Epoch  383\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9459783913565427, 0.8125]\n",
      "Validation -  [0.52, 0.43028846153846156, 0.4418604651162791]\n",
      "Test -  [0.42, 0.4146634615384616, 0.35555555555555557]\n",
      "\n",
      "Epoch  384\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9427771108443377, 0.8085106382978724]\n",
      "Validation -  [0.49, 0.5052083333333333, 0.38554216867469876]\n",
      "Test -  [0.5, 0.46955128205128205, 0.4444444444444445]\n",
      "\n",
      "Epoch  385\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9451780712284914, 0.8080808080808081]\n",
      "Validation -  [0.58, 0.5673076923076923, 0.5116279069767442]\n",
      "Test -  [0.48, 0.48517628205128205, 0.4222222222222222]\n",
      "\n",
      "Epoch  386\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9359743897559023, 0.7872340425531916]\n",
      "Validation -  [0.48, 0.5104166666666666, 0.4090909090909091]\n",
      "Test -  [0.45, 0.3910256410256411, 0.40860215053763443]\n",
      "\n",
      "Epoch  387\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9447779111644659, 0.8367346938775511]\n",
      "Validation -  [0.5, 0.499599358974359, 0.4186046511627907]\n",
      "Test -  [0.4, 0.4122596153846154, 0.3023255813953488]\n",
      "\n",
      "Epoch  388\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9419767907162865, 0.8247422680412372]\n",
      "Validation -  [0.45, 0.4915865384615385, 0.3373493975903615]\n",
      "Test -  [0.41, 0.4046474358974359, 0.3516483516483517]\n",
      "\n",
      "Epoch  389\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9215686274509803, 0.7959183673469387]\n",
      "Validation -  [0.54, 0.5200320512820512, 0.4888888888888889]\n",
      "Test -  [0.44, 0.4178685897435897, 0.3777777777777778]\n",
      "\n",
      "Epoch  390\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9247699079631853, 0.7916666666666666]\n",
      "Validation -  [0.48, 0.516426282051282, 0.3658536585365854]\n",
      "Test -  [0.44, 0.4395032051282052, 0.3913043478260869]\n",
      "\n",
      "Epoch  391\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9699879951980792, 0.8297872340425532]\n",
      "Validation -  [0.47, 0.5080128205128205, 0.3764705882352941]\n",
      "Test -  [0.44, 0.39583333333333337, 0.3488372093023256]\n",
      "\n",
      "Epoch  392\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.932372949179672, 0.8297872340425532]\n",
      "Validation -  [0.5, 0.45873397435897434, 0.375]\n",
      "Test -  [0.52, 0.4719551282051282, 0.4418604651162791]\n",
      "\n",
      "Epoch  393\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9375750300120048, 0.8282828282828283]\n",
      "Validation -  [0.56, 0.5240384615384616, 0.4761904761904762]\n",
      "Test -  [0.44, 0.4399038461538462, 0.4042553191489362]\n",
      "\n",
      "Epoch  394\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9403761504601841, 0.8247422680412372]\n",
      "Validation -  [0.47, 0.48677884615384615, 0.3614457831325301]\n",
      "Test -  [0.44, 0.421474358974359, 0.4166666666666667]\n",
      "\n",
      "Epoch  395\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9303721488595438, 0.8125]\n",
      "Validation -  [0.5, 0.5176282051282052, 0.45652173913043476]\n",
      "Test -  [0.45, 0.46634615384615385, 0.3956043956043956]\n",
      "\n",
      "Epoch  396\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9339735894357744, 0.8125]\n",
      "Validation -  [0.53, 0.5264423076923078, 0.41975308641975306]\n",
      "Test -  [0.44, 0.43028846153846156, 0.4042553191489362]\n",
      "\n",
      "Epoch  397\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9523809523809524, 0.845360824742268]\n",
      "Validation -  [0.58, 0.6109775641025641, 0.5116279069767442]\n",
      "Test -  [0.46, 0.4114583333333333, 0.38636363636363635]\n",
      "\n",
      "Epoch  398\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9543817527010804, 0.8210526315789474]\n",
      "Validation -  [0.56, 0.5180288461538461, 0.4761904761904762]\n",
      "Test -  [0.45, 0.46594551282051283, 0.38202247191011235]\n",
      "\n",
      "Epoch  399\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9463785514205683, 0.8260869565217392]\n",
      "Validation -  [0.54, 0.5412660256410255, 0.45238095238095233]\n",
      "Test -  [0.37, 0.34975961538461536, 0.3636363636363636]\n",
      "\n",
      "Epoch  400\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.88, 0.9563825530212084, 0.8775510204081632]\n",
      "Validation -  [0.52, 0.5068108974358974, 0.4418604651162791]\n",
      "Test -  [0.43, 0.4375, 0.3448275862068966]\n",
      "\n",
      "Epoch  401\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9211684673869548, 0.8125]\n",
      "Validation -  [0.5, 0.49078525641025644, 0.4444444444444445]\n",
      "Test -  [0.45, 0.47836538461538464, 0.40860215053763443]\n",
      "\n",
      "Epoch  402\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9155662264905963, 0.8]\n",
      "Validation -  [0.51, 0.4715544871794872, 0.44943820224719094]\n",
      "Test -  [0.44, 0.4150641025641026, 0.4166666666666667]\n",
      "\n",
      "Epoch  403\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9215686274509803, 0.8]\n",
      "Validation -  [0.58, 0.5681089743589743, 0.5333333333333333]\n",
      "Test -  [0.51, 0.43910256410256415, 0.4615384615384615]\n",
      "\n",
      "Epoch  404\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9139655862344938, 0.7916666666666666]\n",
      "Validation -  [0.46, 0.49999999999999994, 0.41304347826086957]\n",
      "Test -  [0.4, 0.3834134615384615, 0.4]\n",
      "\n",
      "Epoch  405\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9431772709083635, 0.8210526315789474]\n",
      "Validation -  [0.55, 0.5012019230769231, 0.5360824742268041]\n",
      "Test -  [0.43, 0.4158653846153846, 0.37362637362637363]\n",
      "\n",
      "Epoch  406\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9359743897559023, 0.845360824742268]\n",
      "Validation -  [0.62, 0.547676282051282, 0.5777777777777778]\n",
      "Test -  [0.45, 0.47636217948717946, 0.42105263157894735]\n",
      "\n",
      "Epoch  407\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9387755102040817, 0.8367346938775511]\n",
      "Validation -  [0.53, 0.4779647435897436, 0.47191011235955055]\n",
      "Test -  [0.42, 0.41306089743589747, 0.35555555555555557]\n",
      "\n",
      "Epoch  408\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.938375350140056, 0.8333333333333334]\n",
      "Validation -  [0.45, 0.43990384615384615, 0.3956043956043956]\n",
      "Test -  [0.48, 0.44070512820512825, 0.5]\n",
      "\n",
      "Epoch  409\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9571828731492598, 0.8541666666666666]\n",
      "Validation -  [0.52, 0.5076121794871795, 0.5]\n",
      "Test -  [0.44, 0.4298878205128205, 0.4285714285714286]\n",
      "\n",
      "Epoch  410\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9411764705882353, 0.84]\n",
      "Validation -  [0.53, 0.5484775641025641, 0.44705882352941173]\n",
      "Test -  [0.45, 0.42628205128205127, 0.4554455445544555]\n",
      "\n",
      "Epoch  411\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9499799919967988, 0.8571428571428571]\n",
      "Validation -  [0.54, 0.5344551282051282, 0.4772727272727273]\n",
      "Test -  [0.47, 0.4671474358974359, 0.4301075268817204]\n",
      "\n",
      "Epoch  412\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.921968787515006, 0.8125]\n",
      "Validation -  [0.52, 0.5028044871794872, 0.42857142857142855]\n",
      "Test -  [0.46, 0.47115384615384615, 0.41304347826086957]\n",
      "\n",
      "Epoch  413\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9263705482192879, 0.8541666666666666]\n",
      "Validation -  [0.5, 0.5060096153846154, 0.4680851063829787]\n",
      "Test -  [0.46, 0.41466346153846156, 0.41304347826086957]\n",
      "\n",
      "Epoch  414\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9291716686674669, 0.8333333333333334]\n",
      "Validation -  [0.51, 0.5408653846153846, 0.3950617283950617]\n",
      "Test -  [0.44, 0.41025641025641024, 0.4166666666666667]\n",
      "\n",
      "Epoch  415\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9351740696278511, 0.8]\n",
      "Validation -  [0.5, 0.5288461538461539, 0.43181818181818177]\n",
      "Test -  [0.39, 0.3729967948717949, 0.32967032967032966]\n",
      "\n",
      "Epoch  416\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9443777511004401, 0.8247422680412372]\n",
      "Validation -  [0.47, 0.5120192307692307, 0.4301075268817204]\n",
      "Test -  [0.47, 0.43950320512820507, 0.45360824742268036]\n",
      "\n",
      "Epoch  417\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9507803121248499, 0.845360824742268]\n",
      "Validation -  [0.47, 0.4635416666666667, 0.40449438202247195]\n",
      "Test -  [0.46, 0.36498397435897434, 0.39999999999999997]\n",
      "\n",
      "Epoch  418\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9259703881552621, 0.8210526315789474]\n",
      "Validation -  [0.48, 0.48237179487179493, 0.4090909090909091]\n",
      "Test -  [0.41, 0.39903846153846156, 0.3218390804597701]\n",
      "\n",
      "Epoch  419\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9295718287314926, 0.8367346938775511]\n",
      "Validation -  [0.55, 0.5320512820512822, 0.5054945054945056]\n",
      "Test -  [0.46, 0.4451121794871795, 0.41304347826086957]\n",
      "\n",
      "Epoch  420\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9367747098839536, 0.8247422680412372]\n",
      "Validation -  [0.55, 0.5556891025641025, 0.4827586206896552]\n",
      "Test -  [0.43, 0.42868589743589747, 0.37362637362637363]\n",
      "\n",
      "Epoch  421\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9343737494997999, 0.8]\n",
      "Validation -  [0.54, 0.5268429487179487, 0.425]\n",
      "Test -  [0.43, 0.42467948717948717, 0.37362637362637363]\n",
      "\n",
      "Epoch  422\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9235694277711084, 0.8163265306122448]\n",
      "Validation -  [0.5, 0.516025641025641, 0.45652173913043476]\n",
      "Test -  [0.39, 0.3874198717948718, 0.34408602150537637]\n",
      "\n",
      "Epoch  423\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9351740696278511, 0.8333333333333334]\n",
      "Validation -  [0.52, 0.44270833333333337, 0.4146341463414634]\n",
      "Test -  [0.5, 0.45753205128205127, 0.43181818181818177]\n",
      "\n",
      "Epoch  424\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9523809523809524, 0.8571428571428571]\n",
      "Validation -  [0.52, 0.5300480769230769, 0.4418604651162791]\n",
      "Test -  [0.43, 0.4182692307692307, 0.37362637362637363]\n",
      "\n",
      "Epoch  425\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9459783913565426, 0.8571428571428571]\n",
      "Validation -  [0.55, 0.5797275641025641, 0.5054945054945056]\n",
      "Test -  [0.39, 0.4314903846153846, 0.34408602150537637]\n",
      "\n",
      "Epoch  426\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.941576630652261, 0.8421052631578948]\n",
      "Validation -  [0.53, 0.5220352564102564, 0.4835164835164835]\n",
      "Test -  [0.5, 0.45953525641025644, 0.4680851063829787]\n",
      "\n",
      "Epoch  427\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.945578231292517, 0.8247422680412372]\n",
      "Validation -  [0.5, 0.5136217948717948, 0.4444444444444445]\n",
      "Test -  [0.38, 0.36258012820512825, 0.3541666666666667]\n",
      "\n",
      "Epoch  428\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9503801520608244, 0.865979381443299]\n",
      "Validation -  [0.5, 0.4983974358974359, 0.4897959183673469]\n",
      "Test -  [0.43, 0.45953525641025644, 0.37362637362637363]\n",
      "\n",
      "Epoch  429\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.95078031212485, 0.8571428571428571]\n",
      "Validation -  [0.49, 0.4923878205128205, 0.45161290322580644]\n",
      "Test -  [0.38, 0.38982371794871795, 0.3404255319148936]\n",
      "\n",
      "Epoch  430\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.933173269307723, 0.8247422680412372]\n",
      "Validation -  [0.57, 0.5645032051282052, 0.5567010309278351]\n",
      "Test -  [0.43, 0.4238782051282051, 0.38709677419354843]\n",
      "\n",
      "Epoch  431\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9363745498199278, 0.8080808080808081]\n",
      "Validation -  [0.53, 0.563701923076923, 0.4946236559139785]\n",
      "Test -  [0.41, 0.4154647435897436, 0.4158415841584158]\n",
      "\n",
      "Epoch  432\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9131652661064427, 0.8247422680412372]\n",
      "Validation -  [0.52, 0.4651442307692308, 0.4418604651162791]\n",
      "Test -  [0.49, 0.43830128205128205, 0.48484848484848486]\n",
      "\n",
      "Epoch  433\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9347739095638256, 0.7959183673469387]\n",
      "Validation -  [0.51, 0.4731570512820513, 0.42352941176470593]\n",
      "Test -  [0.46, 0.4030448717948718, 0.4375]\n",
      "\n",
      "Epoch  434\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9291716686674669, 0.8282828282828283]\n",
      "Validation -  [0.54, 0.532051282051282, 0.45238095238095233]\n",
      "Test -  [0.47, 0.4182692307692308, 0.4175824175824176]\n",
      "\n",
      "Epoch  435\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9247699079631853, 0.8]\n",
      "Validation -  [0.56, 0.5328525641025641, 0.4883720930232558]\n",
      "Test -  [0.45, 0.4174679487179487, 0.43298969072164945]\n",
      "\n",
      "Epoch  436\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.932372949179672, 0.8247422680412372]\n",
      "Validation -  [0.56, 0.5568910256410257, 0.5]\n",
      "Test -  [0.42, 0.41306089743589747, 0.35555555555555557]\n",
      "\n",
      "Epoch  437\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.78, 0.9259703881552621, 0.7659574468085107]\n",
      "Validation -  [0.5, 0.5388621794871795, 0.39024390243902435]\n",
      "Test -  [0.47, 0.45753205128205127, 0.45360824742268036]\n",
      "\n",
      "Epoch  438\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9311724689875951, 0.8210526315789474]\n",
      "Validation -  [0.57, 0.5340544871794872, 0.5376344086021506]\n",
      "Test -  [0.47, 0.4387019230769231, 0.40449438202247195]\n",
      "\n",
      "Epoch  439\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9419767907162866, 0.8316831683168315]\n",
      "Validation -  [0.55, 0.5328525641025641, 0.4578313253012048]\n",
      "Test -  [0.48, 0.5024038461538461, 0.44680851063829785]\n",
      "\n",
      "Epoch  440\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9227691076430572, 0.7789473684210527]\n",
      "Validation -  [0.5, 0.5028044871794872, 0.43181818181818177]\n",
      "Test -  [0.43, 0.40464743589743596, 0.3294117647058824]\n",
      "\n",
      "Epoch  441\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9403761504601841, 0.8333333333333334]\n",
      "Validation -  [0.56, 0.5556891025641025, 0.5]\n",
      "Test -  [0.44, 0.405849358974359, 0.3488372093023256]\n",
      "\n",
      "Epoch  442\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9275710284113645, 0.8431372549019607]\n",
      "Validation -  [0.47, 0.45312500000000006, 0.3908045977011494]\n",
      "Test -  [0.46, 0.40745192307692313, 0.39999999999999997]\n",
      "\n",
      "Epoch  443\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.78, 0.9247699079631853, 0.7708333333333334]\n",
      "Validation -  [0.53, 0.5316506410256411, 0.44705882352941173]\n",
      "Test -  [0.42, 0.3934294871794872, 0.3829787234042554]\n",
      "\n",
      "Epoch  444\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9535814325730292, 0.8686868686868686]\n",
      "Validation -  [0.56, 0.5360576923076923, 0.4883720930232558]\n",
      "Test -  [0.5, 0.48958333333333337, 0.4444444444444445]\n",
      "\n",
      "Epoch  445\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9339735894357744, 0.7789473684210527]\n",
      "Validation -  [0.46, 0.44911858974358976, 0.38636363636363635]\n",
      "Test -  [0.47, 0.4559294871794872, 0.45360824742268036]\n",
      "\n",
      "Epoch  446\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9427771108443377, 0.8085106382978724]\n",
      "Validation -  [0.55, 0.5028044871794872, 0.5054945054945056]\n",
      "Test -  [0.45, 0.4206730769230769, 0.40860215053763443]\n",
      "\n",
      "Epoch  447\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9447779111644659, 0.8172043010752689]\n",
      "Validation -  [0.52, 0.4907852564102564, 0.4666666666666667]\n",
      "Test -  [0.46, 0.44310897435897434, 0.372093023255814]\n",
      "\n",
      "Epoch  448\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9463785514205683, 0.84]\n",
      "Validation -  [0.53, 0.48838141025641024, 0.44705882352941173]\n",
      "Test -  [0.46, 0.41145833333333326, 0.39999999999999997]\n",
      "\n",
      "Epoch  449\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9503801520608244, 0.851063829787234]\n",
      "Validation -  [0.52, 0.5120192307692307, 0.4782608695652174]\n",
      "Test -  [0.46, 0.4707532051282051, 0.39999999999999997]\n",
      "\n",
      "Epoch  450\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.957983193277311, 0.8686868686868686]\n",
      "Validation -  [0.52, 0.5132211538461539, 0.4666666666666667]\n",
      "Test -  [0.44, 0.3782051282051282, 0.4166666666666667]\n",
      "\n",
      "Epoch  451\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9447779111644659, 0.8333333333333334]\n",
      "Validation -  [0.54, 0.5208333333333334, 0.5106382978723404]\n",
      "Test -  [0.47, 0.44711538461538464, 0.46464646464646464]\n",
      "\n",
      "Epoch  452\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9399759903961585, 0.8247422680412372]\n",
      "Validation -  [0.49, 0.5256410256410255, 0.46315789473684216]\n",
      "Test -  [0.45, 0.42948717948717946, 0.38202247191011235]\n",
      "\n",
      "Epoch  453\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9419767907162866, 0.8541666666666666]\n",
      "Validation -  [0.56, 0.5408653846153846, 0.5217391304347826]\n",
      "Test -  [0.42, 0.4026442307692308, 0.3695652173913044]\n",
      "\n",
      "Epoch  454\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9175670268107243, 0.7916666666666666]\n",
      "Validation -  [0.6, 0.5528846153846153, 0.5348837209302326]\n",
      "Test -  [0.45, 0.4495192307692308, 0.4444444444444445]\n",
      "\n",
      "Epoch  455\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9295718287314925, 0.787878787878788]\n",
      "Validation -  [0.5, 0.47516025641025644, 0.4444444444444445]\n",
      "Test -  [0.42, 0.3641826923076923, 0.32558139534883723]\n",
      "\n",
      "Epoch  456\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9211684673869548, 0.7872340425531916]\n",
      "Validation -  [0.59, 0.5204326923076924, 0.5060240963855421]\n",
      "Test -  [0.5, 0.47516025641025644, 0.4791666666666667]\n",
      "\n",
      "Epoch  457\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9259703881552621, 0.8172043010752689]\n",
      "Validation -  [0.49, 0.4679487179487179, 0.3703703703703703]\n",
      "Test -  [0.42, 0.3958333333333333, 0.35555555555555557]\n",
      "\n",
      "Epoch  458\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9463785514205683, 0.8043478260869564]\n",
      "Validation -  [0.56, 0.5220352564102564, 0.4761904761904762]\n",
      "Test -  [0.47, 0.44591346153846156, 0.4175824175824176]\n",
      "\n",
      "Epoch  459\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9367747098839536, 0.7835051546391751]\n",
      "Validation -  [0.55, 0.5580929487179487, 0.4444444444444444]\n",
      "Test -  [0.5, 0.5244391025641026, 0.4444444444444445]\n",
      "\n",
      "Epoch  460\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9439775910364145, 0.845360824742268]\n",
      "Validation -  [0.57, 0.5568910256410257, 0.4941176470588235]\n",
      "Test -  [0.42, 0.43990384615384615, 0.3695652173913044]\n",
      "\n",
      "Epoch  461\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.78, 0.9103641456582633, 0.7608695652173912]\n",
      "Validation -  [0.48, 0.4807692307692308, 0.380952380952381]\n",
      "Test -  [0.49, 0.4667467948717948, 0.41379310344827586]\n",
      "\n",
      "Epoch  462\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9247699079631853, 0.8247422680412372]\n",
      "Validation -  [0.51, 0.4975961538461538, 0.4731182795698925]\n",
      "Test -  [0.45, 0.41626602564102566, 0.36781609195402293]\n",
      "\n",
      "Epoch  463\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9391756702681072, 0.845360824742268]\n",
      "Validation -  [0.5, 0.49399038461538464, 0.43181818181818177]\n",
      "Test -  [0.5, 0.4499198717948718, 0.45652173913043476]\n",
      "\n",
      "Epoch  464\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9459783913565427, 0.8484848484848485]\n",
      "Validation -  [0.54, 0.5360576923076923, 0.4888888888888889]\n",
      "Test -  [0.42, 0.4030448717948718, 0.35555555555555557]\n",
      "\n",
      "Epoch  465\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9367747098839536, 0.8210526315789474]\n",
      "Validation -  [0.45, 0.4583333333333333, 0.3529411764705882]\n",
      "Test -  [0.45, 0.41065705128205127, 0.42105263157894735]\n",
      "\n",
      "Epoch  466\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9491796718687475, 0.8484848484848485]\n",
      "Validation -  [0.48, 0.4415064102564103, 0.3658536585365854]\n",
      "Test -  [0.43, 0.4030448717948718, 0.38709677419354843]\n",
      "\n",
      "Epoch  467\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.932372949179672, 0.8247422680412372]\n",
      "Validation -  [0.51, 0.5068108974358975, 0.42352941176470593]\n",
      "Test -  [0.49, 0.4411057692307693, 0.46315789473684216]\n",
      "\n",
      "Epoch  468\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.88, 0.9523809523809522, 0.8749999999999999]\n",
      "Validation -  [0.56, 0.5849358974358975, 0.4883720930232558]\n",
      "Test -  [0.5, 0.4727564102564103, 0.4680851063829787]\n",
      "\n",
      "Epoch  469\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.938375350140056, 0.8431372549019607]\n",
      "Validation -  [0.46, 0.4751602564102564, 0.41304347826086957]\n",
      "Test -  [0.45, 0.4431089743589744, 0.3956043956043956]\n",
      "\n",
      "Epoch  470\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9307723089235693, 0.8247422680412372]\n",
      "Validation -  [0.55, 0.546875, 0.5161290322580646]\n",
      "Test -  [0.51, 0.4262820512820513, 0.4731182795698925]\n",
      "\n",
      "Epoch  471\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9267707082833132, 0.8085106382978724]\n",
      "Validation -  [0.48, 0.43669871794871795, 0.4222222222222222]\n",
      "Test -  [0.46, 0.45552884615384615, 0.39999999999999997]\n",
      "\n",
      "Epoch  472\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9339735894357744, 0.8163265306122448]\n",
      "Validation -  [0.52, 0.5256410256410257, 0.45454545454545453]\n",
      "Test -  [0.49, 0.46434294871794873, 0.45161290322580644]\n",
      "\n",
      "Epoch  473\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9243697478991596, 0.8247422680412372]\n",
      "Validation -  [0.55, 0.5360576923076923, 0.5263157894736842]\n",
      "Test -  [0.44, 0.42948717948717946, 0.3777777777777778]\n",
      "\n",
      "Epoch  474\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.79, 0.9315726290516206, 0.787878787878788]\n",
      "Validation -  [0.52, 0.5244391025641025, 0.4782608695652174]\n",
      "Test -  [0.48, 0.44631410256410253, 0.4583333333333333]\n",
      "\n",
      "Epoch  475\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9211684673869548, 0.8125]\n",
      "Validation -  [0.49, 0.5264423076923077, 0.45161290322580644]\n",
      "Test -  [0.41, 0.39142628205128205, 0.3655913978494624]\n",
      "\n",
      "Epoch  476\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9411764705882353, 0.8080808080808081]\n",
      "Validation -  [0.54, 0.5372596153846153, 0.4888888888888889]\n",
      "Test -  [0.42, 0.39623397435897434, 0.3695652173913044]\n",
      "\n",
      "Epoch  477\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9443777511004401, 0.8297872340425532]\n",
      "Validation -  [0.51, 0.4803685897435897, 0.44943820224719094]\n",
      "Test -  [0.44, 0.4395032051282051, 0.3636363636363636]\n",
      "\n",
      "Epoch  478\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.87, 0.9519807923169268, 0.8712871287128714]\n",
      "Validation -  [0.55, 0.530448717948718, 0.49438202247191015]\n",
      "Test -  [0.43, 0.4086538461538462, 0.38709677419354843]\n",
      "\n",
      "Epoch  479\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.938375350140056, 0.8484848484848485]\n",
      "Validation -  [0.54, 0.514423076923077, 0.45238095238095233]\n",
      "Test -  [0.5, 0.43750000000000006, 0.4680851063829787]\n",
      "\n",
      "Epoch  480\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9251700680272108, 0.8210526315789474]\n",
      "Validation -  [0.48, 0.4775641025641026, 0.3953488372093023]\n",
      "Test -  [0.37, 0.35857371794871795, 0.30769230769230776]\n",
      "\n",
      "Epoch  481\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9359743897559023, 0.8200000000000001]\n",
      "Validation -  [0.54, 0.5020032051282051, 0.46511627906976744]\n",
      "Test -  [0.47, 0.43830128205128205, 0.4301075268817204]\n",
      "\n",
      "Epoch  482\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.938375350140056, 0.8421052631578948]\n",
      "Validation -  [0.48, 0.46434294871794873, 0.3953488372093023]\n",
      "Test -  [0.42, 0.3922275641025641, 0.35555555555555557]\n",
      "\n",
      "Epoch  483\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9459783913565426, 0.8247422680412372]\n",
      "Validation -  [0.53, 0.516025641025641, 0.44705882352941173]\n",
      "Test -  [0.43, 0.4178685897435897, 0.38709677419354843]\n",
      "\n",
      "Epoch  484\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9151660664265707, 0.8043478260869564]\n",
      "Validation -  [0.51, 0.49479166666666663, 0.42352941176470593]\n",
      "Test -  [0.43, 0.4443108974358974, 0.39999999999999997]\n",
      "\n",
      "Epoch  485\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.946778711484594, 0.8367346938775511]\n",
      "Validation -  [0.54, 0.5536858974358975, 0.46511627906976744]\n",
      "Test -  [0.39, 0.39302884615384615, 0.34408602150537637]\n",
      "\n",
      "Epoch  486\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9407763105242096, 0.8421052631578948]\n",
      "Validation -  [0.54, 0.5428685897435898, 0.4888888888888889]\n",
      "Test -  [0.41, 0.35657051282051283, 0.33707865168539325]\n",
      "\n",
      "Epoch  487\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.89, 0.9419767907162866, 0.888888888888889]\n",
      "Validation -  [0.52, 0.5544871794871795, 0.4418604651162791]\n",
      "Test -  [0.43, 0.4194711538461539, 0.38709677419354843]\n",
      "\n",
      "Epoch  488\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9395758303321329, 0.8]\n",
      "Validation -  [0.54, 0.5572916666666666, 0.45238095238095233]\n",
      "Test -  [0.43, 0.4090544871794872, 0.35955056179775274]\n",
      "\n",
      "Epoch  489\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9451780712284914, 0.8297872340425532]\n",
      "Validation -  [0.5, 0.4895833333333333, 0.4444444444444445]\n",
      "Test -  [0.43, 0.437099358974359, 0.38709677419354843]\n",
      "\n",
      "Epoch  490\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.8, 0.9327731092436975, 0.7916666666666666]\n",
      "Validation -  [0.51, 0.5360576923076924, 0.42352941176470593]\n",
      "Test -  [0.47, 0.45953525641025633, 0.46464646464646464]\n",
      "\n",
      "Epoch  491\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.89, 0.9583833533413365, 0.8865979381443299]\n",
      "Validation -  [0.55, 0.5276442307692307, 0.47058823529411764]\n",
      "Test -  [0.48, 0.4579326923076923, 0.4583333333333333]\n",
      "\n",
      "Epoch  492\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.86, 0.9483793517406963, 0.851063829787234]\n",
      "Validation -  [0.55, 0.5112179487179487, 0.49438202247191015]\n",
      "Test -  [0.43, 0.41947115384615385, 0.39999999999999997]\n",
      "\n",
      "Epoch  493\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.88, 0.9503801520608244, 0.8749999999999999]\n",
      "Validation -  [0.48, 0.5036057692307692, 0.3953488372093023]\n",
      "Test -  [0.44, 0.39463141025641024, 0.3913043478260869]\n",
      "\n",
      "Epoch  494\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.81, 0.9359743897559023, 0.8041237113402062]\n",
      "Validation -  [0.51, 0.5316506410256411, 0.4731182795698925]\n",
      "Test -  [0.47, 0.436298076923077, 0.4301075268817204]\n",
      "\n",
      "Epoch  495\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9491796718687475, 0.8163265306122448]\n",
      "Validation -  [0.52, 0.5544871794871794, 0.45454545454545453]\n",
      "Test -  [0.49, 0.39903846153846156, 0.45161290322580644]\n",
      "\n",
      "Epoch  496\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.85, 0.9507803121248499, 0.8484848484848485]\n",
      "Validation -  [0.54, 0.5020032051282051, 0.5]\n",
      "Test -  [0.44, 0.40104166666666663, 0.3913043478260869]\n",
      "\n",
      "Epoch  497\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.82, 0.9403761504601841, 0.8125]\n",
      "Validation -  [0.51, 0.5068108974358975, 0.42352941176470593]\n",
      "Test -  [0.43, 0.4010416666666667, 0.39999999999999997]\n",
      "\n",
      "Epoch  498\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.84, 0.9423769507803121, 0.84]\n",
      "Validation -  [0.48, 0.47716346153846156, 0.4222222222222222]\n",
      "Test -  [0.43, 0.42628205128205127, 0.43564356435643564]\n",
      "\n",
      "Epoch  499\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.0\n",
      "Train -  [0.83, 0.9387755102040816, 0.8282828282828283]\n",
      "Validation -  [0.52, 0.5216346153846154, 0.4782608695652174]\n",
      "Test -  [0.47, 0.43509615384615385, 0.4175824175824176]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for epoch in range(500):  # loop over the dataset multiple times\n",
    "    print (\"\\nEpoch \", epoch)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i in range(int(len(X_train)/batch_size-1)):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = torch.from_numpy(X_train[s:e])\n",
    "        labels = torch.FloatTensor(np.array([y_train[s:e]]).T*1.0)\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        #running_loss = running_loss + loss.data[0]\n",
    "    \n",
    "    # Validation accuracy\n",
    "    params = [\"acc\", \"auc\", \"fmeasure\"]\n",
    "    print (params)\n",
    "    print (\"Training Loss \", running_loss)\n",
    "    print (\"Train - \", evaluate(net, X_train, y_train, params))\n",
    "    print (\"Validation - \", evaluate(net, X_val, y_val, params))\n",
    "    print (\"Test - \", evaluate(net, X_test, y_test, params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
